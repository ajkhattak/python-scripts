{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "sys.path.append('/Users/ajc/Core/SimDataInputs/ats-repo/ats-Aug6/tools/utils/')\n",
    "sys.path.append('/Users/ajc/Core/PostProcessData/PyScript')\n",
    "import readdata as rd\n",
    "import parse_ats, transect_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = '/Users/ajc/AllPostProcessData/BarrowTransect/NGEE/Temperature-SiteC/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor c in data5.columns:\\n    k = -100\\n    if 'trough' in c or 'center' in c or 'rim' in c:\\n        k = int(float(c[6:10])*100)\\n        dat = np.array([ x + 273.15  for x in data5[c]])\\n        d = np.array([dat[i-1] if np.isnan(x) else x for i,x in enumerate(dat)])\\n    if 'trough' in c:\\n        DataObserved2016['temperature-trough-%scm'%k] = d\\n    elif 'center' in c and not 'off' in c :\\n        DataObserved2016['temperature-center-%scm'%k] = d\\n    elif 'rim' in c and 'rim2' not in c:\\n        if k > 2:\\n            k = k + 1*0\\n        DataObserved2016['temperature-rim-%scm'%k] = d\\n        \\n        \\n    if 'Time' in c:\\n        time1 = [pd.to_datetime(data5['Timestamp'])]\\n        time = [(t - time_origin).dt.total_seconds()/86400 for t in time1]\\n        Time = np.array([start_year +t/365. for t in time[0]])\\n        #Time = np.array([t for t in time[0]])\\n        DataObserved2016['time'] = np.array(Time)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile = '/Users/ajc/Core/SimDataInputs/observed_data_barrow/Vladimir-Data/Area_C/'\n",
    "save = False\n",
    "\n",
    "dataset1= 'NGEE_BRW_C_2012-09-09_2013-09-30_Thermal_Transect_and_Borehole.csv' # 2012-13\n",
    "dataset2= 'NGEE_BRW_C_2013-10-01_2014-09-30_Thermal_Transect_and_Borehole.csv' # 2013-14\n",
    "dataset3= 'NGEE_BRW_C_2014-10-01_2015-09-30_Thermal_Transect_and_Borehole.csv' # 2014-15\n",
    "dataset4= 'NGEE_BRW_C_2015-10-01_2016-09-30_Thermal_Transect_and_Borehole.csv' # 2015-16\n",
    "#dataset5= 'NGEE_BRW_C_2016-10-01_2017-09-30_Thermal_Transect_and_Borehole.csv' # 2014-15\n",
    "\n",
    "time_origin = datetime.datetime(2010,1,1,0,0,0)\n",
    "\n",
    "infile_observed1 = infile + dataset1\n",
    "infile_observed2 = infile + dataset2\n",
    "infile_observed3 = infile + dataset3\n",
    "infile_observed4 = infile + dataset4\n",
    "#infile_observed5 = infile + dataset5\n",
    "data1 = pd.read_csv(infile_observed1, skiprows=5)\n",
    "data2 = pd.read_csv(infile_observed2, skiprows=5)\n",
    "data3 = pd.read_csv(infile_observed3, skiprows=5)\n",
    "data4 = pd.read_csv(infile_observed4, skiprows=5)\n",
    "#data5 = pd.read_csv(infile_observed5, skiprows=5)\n",
    "\n",
    "DataObserved2012 = dict()\n",
    "DataObserved2013 = dict()\n",
    "DataObserved2014 = dict()\n",
    "DataObserved2015 = dict()\n",
    "DataObserved2016 = dict()\n",
    "start_year = 2010\n",
    "for c in data1.columns:\n",
    "    k = -100\n",
    "    if 'trough' in c or 'center' in c or 'rim' in c:\n",
    "        k = int(float(c[6:10])*100)\n",
    "        dat = np.array([ x + 273.15  for x in data1[c]])\n",
    "        d = np.array([dat[i-1] if np.isnan(x) else x for i,x in enumerate(dat)])\n",
    "        \n",
    "    if 'trough' in c:\n",
    "        DataObserved2012['temperature-trough-%scm'%k] = d\n",
    "    elif 'center' in c and not 'off' in c :\n",
    "        DataObserved2012['temperature-center-%scm'%k] = d\n",
    "    elif 'rim' in c and 'rim2' not in c:\n",
    "        if k > 2:\n",
    "            k = k + 1*0\n",
    "        DataObserved2012['temperature-rim-%scm'%k] = d\n",
    "        \n",
    "    if 'Time' in c:\n",
    "        time1 = [pd.to_datetime(data1['Timestamp'])]\n",
    "        time = [(t - time_origin).dt.total_seconds()/86400 for t in time1]\n",
    "        Time = np.array([start_year + t/365. for t in time[0]])\n",
    "        #Time = np.array([t for t in time[0]])\n",
    "        DataObserved2012['time'] = np.array(Time)\n",
    "\n",
    "for c in data2.columns:\n",
    "    k = -100\n",
    "    if 'trough' in c or 'center' in c or 'rim' in c:\n",
    "        k = int(float(c[6:10])*100)\n",
    "        dat = np.array([ x + 273.15  for x in data2[c]])\n",
    "        d = np.array([dat[i-1] if np.isnan(x) else x for i,x in enumerate(dat)])\n",
    "    if 'trough' in c:\n",
    "        DataObserved2013['temperature-trough-%scm'%k] = d\n",
    "    elif 'center' in c and not 'off' in c :\n",
    "        DataObserved2013['temperature-center-%scm'%k] = d\n",
    "    elif 'rim' in c and 'rim2' not in c:\n",
    "        DataObserved2013['temperature-rim-%scm'%k] = d\n",
    "    if 'Time' in c:\n",
    "        time1 = [pd.to_datetime(data2['Timestamp'])]\n",
    "        time = [(t - time_origin).dt.total_seconds()/86400 for t in time1]\n",
    "        Time = np.array([start_year +t/365. for t in time[0]])\n",
    "        #Time = np.array([t for t in time[0]])\n",
    "        DataObserved2013['time'] = np.array(Time)\n",
    "        \n",
    "    \n",
    "for c in data3.columns:\n",
    "    k = -100\n",
    "    if 'trough' in c or 'center' in c or 'rim' in c:\n",
    "        k = int(float(c[6:10])*100)\n",
    "        dat = np.array([ x + 273.15  for x in data3[c]])\n",
    "        d = np.array([dat[i-1] if np.isnan(x) else x for i,x in enumerate(dat)])\n",
    "    if 'trough' in c:\n",
    "        DataObserved2014['temperature-trough-%scm'%k] = d\n",
    "    elif 'center' in c and not 'off' in c :\n",
    "        DataObserved2014['temperature-center-%scm'%k] = d\n",
    "    elif 'rim' in c and 'rim2' not in c:\n",
    "        DataObserved2014['temperature-rim-%scm'%k] = d\n",
    "    if 'Time' in c:\n",
    "        time1 = [pd.to_datetime(data3['Timestamp'])]\n",
    "        time = [(t - time_origin).dt.total_seconds()/86400 for t in time1]\n",
    "        Time = np.array([start_year +t/365. for t in time[0]])\n",
    "        #Time = np.array([t for t in time[0]])\n",
    "        DataObserved2014['time'] = np.array(Time)\n",
    "\n",
    "for c in data4.columns:\n",
    "    k = -100\n",
    "    if 'trough' in c or 'center' in c or 'rim' in c:\n",
    "        k = int(float(c[6:10])*100)\n",
    "        dat = np.array([ x + 273.15  for x in data4[c]])\n",
    "        d = np.array([dat[i-1] if np.isnan(x) else x for i,x in enumerate(dat)])\n",
    "    if 'trough' in c:\n",
    "        DataObserved2015['temperature-trough-%scm'%k] = d\n",
    "    elif 'center' in c and not 'off' in c :\n",
    "        DataObserved2015['temperature-center-%scm'%k] = d\n",
    "    elif 'rim' in c and 'rim2' not in c:\n",
    "        if k > 2:\n",
    "            k = k + 1*0\n",
    "        DataObserved2015['temperature-rim-%scm'%k] = d\n",
    "        \n",
    "    if 'Time' in c:\n",
    "        time1 = [pd.to_datetime(data4['Timestamp'])]\n",
    "        time = [(t - time_origin).dt.total_seconds()/86400 for t in time1]\n",
    "        Time = np.array([start_year +t/365. for t in time[0]])\n",
    "        #Time = np.array([t for t in time[0]])\n",
    "        DataObserved2015['time'] = np.array(Time)\n",
    "\"\"\"\n",
    "for c in data5.columns:\n",
    "    k = -100\n",
    "    if 'trough' in c or 'center' in c or 'rim' in c:\n",
    "        k = int(float(c[6:10])*100)\n",
    "        dat = np.array([ x + 273.15  for x in data5[c]])\n",
    "        d = np.array([dat[i-1] if np.isnan(x) else x for i,x in enumerate(dat)])\n",
    "    if 'trough' in c:\n",
    "        DataObserved2016['temperature-trough-%scm'%k] = d\n",
    "    elif 'center' in c and not 'off' in c :\n",
    "        DataObserved2016['temperature-center-%scm'%k] = d\n",
    "    elif 'rim' in c and 'rim2' not in c:\n",
    "        if k > 2:\n",
    "            k = k + 1*0\n",
    "        DataObserved2016['temperature-rim-%scm'%k] = d\n",
    "        \n",
    "        \n",
    "    if 'Time' in c:\n",
    "        time1 = [pd.to_datetime(data5['Timestamp'])]\n",
    "        time = [(t - time_origin).dt.total_seconds()/86400 for t in time1]\n",
    "        Time = np.array([start_year +t/365. for t in time[0]])\n",
    "        #Time = np.array([t for t in time[0]])\n",
    "        DataObserved2016['time'] = np.array(Time)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Snow\n",
    "def ObservedSnow(location='Center'):\n",
    "    SnowData = dict()\n",
    "    infile = '/Users/ajc/Desktop/SimDataInputs/barrow-polygon-data/Vladimir-Data/SnowDepth/'\n",
    "    infile_observed1 = infile + 'C_Snow_%s_2012-2013.csv'%location\n",
    "    infile_observed2 = infile + 'C_Snow_%s_2013-2014.csv'%location\n",
    "    datasnow1 = pd.read_csv(infile_observed1,skiprows=3)\n",
    "    datasnow2 = pd.read_csv(infile_observed2,skiprows=3)\n",
    "\n",
    "    dat1 = np.array([ x for x in datasnow1['1 Hour Moving Average']])\n",
    "    dat2 = np.array([ x for x in datasnow2['1 Hour Moving Average']])\n",
    "    \n",
    "    #SnowData1 = np.array([x/100. if x < 50 else .5 for i,x in enumerate(dat1)])\n",
    "    #SnowData2 = np.array([x/100. if x < 50 else .5 for i,x in enumerate(dat2)])\n",
    "    \n",
    "    SnowData1 = np.array([x/1. for i,x in enumerate(dat1)])\n",
    "    SnowData2 = np.array([x/1. for i,x in enumerate(dat2)])\n",
    "    \n",
    "    time1 = [pd.to_datetime(datasnow1['TZ=UTC+0'])]\n",
    "    time = np.array([(t - time_origin).dt.total_seconds()/86400 for t in time1])\n",
    "    TimeSnow1 = np.array([t/365.25 for t in time[0]])\n",
    "    \n",
    "    \n",
    "    time1 = [pd.to_datetime(datasnow2['TZ=UTC+0'])]\n",
    "    time = np.array([(t - time_origin).dt.total_seconds()/86400 for t in time1])\n",
    "    TimeSnow2 = np.array([t/365.25 for t in time[0]])\n",
    "    \n",
    "   \n",
    "    mask = np.ones(len(SnowData1), dtype=bool)\n",
    "    for i,d in enumerate(SnowData1):\n",
    "        if d > 6000 or d < 0:\n",
    "            mask[i] = False\n",
    "    SnowData1 = SnowData1[mask]\n",
    "    TimeSnow1 = TimeSnow1[mask]\n",
    "    SnowData1 = SnowData1 / 100.\n",
    "    L1 = len(SnowData1) - len(SnowData1)%24\n",
    "    \n",
    "    SnowData1 = np.reshape(SnowData1[:L1], (-1,24)).mean(axis=1)\n",
    "    TimeSnow1 = np.reshape(TimeSnow1[:L1], (-1,24)).mean(axis=1)\n",
    "    \n",
    "    mask = np.ones(len(SnowData2), dtype=bool)\n",
    "    for i,d in enumerate(SnowData2):\n",
    "        if d > 6000 or d < 0:\n",
    "            mask[i] = False\n",
    "    SnowData2 = SnowData2[mask]\n",
    "    TimeSnow2 = TimeSnow2[mask]\n",
    "\n",
    "    SnowData2 = SnowData2 / 100.\n",
    "    \n",
    "    L2 = len(SnowData2) - len(SnowData2)%24\n",
    "    \n",
    "    SnowData2 = np.reshape(SnowData2[:L2], (-1,24)).mean(axis=1)\n",
    "    TimeSnow2 = np.reshape(TimeSnow2[:L2], (-1,24)).mean(axis=1)\n",
    "    SnowData['snow_time_%s'%location] = np.concatenate((TimeSnow1, TimeSnow2))\n",
    "    SnowData['snow_depth_%s'%location] = np.concatenate((SnowData1,SnowData2))\n",
    "\n",
    "    return SnowData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/Users/ajc/Desktop/SimDataInputs/barrow-polygon-data/Vladimir-Data/SnowDepth/C_Snow_Center_2012-2013.csv' does not exist: b'/Users/ajc/Desktop/SimDataInputs/barrow-polygon-data/Vladimir-Data/SnowDepth/C_Snow_Center_2012-2013.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-213608faab62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDataObservedSnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mDataObservedSnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObservedSnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Center'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObservedSnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Rim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0md3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObservedSnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trough'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d13db6b06f00>\u001b[0m in \u001b[0;36mObservedSnow\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minfile_observed1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'C_Snow_%s_2012-2013.csv'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minfile_observed2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'C_Snow_%s_2013-2014.csv'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdatasnow1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile_observed1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdatasnow2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile_observed2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/Users/ajc/Desktop/SimDataInputs/barrow-polygon-data/Vladimir-Data/SnowDepth/C_Snow_Center_2012-2013.csv' does not exist: b'/Users/ajc/Desktop/SimDataInputs/barrow-polygon-data/Vladimir-Data/SnowDepth/C_Snow_Center_2012-2013.csv'"
     ]
    }
   ],
   "source": [
    "DataObservedSnow = dict()\n",
    "\n",
    "DataObservedSnow = ObservedSnow('Center')\n",
    "d2 = ObservedSnow('Rim')\n",
    "d3 = ObservedSnow('Trough')\n",
    "DataObservedSnow.update(d2)\n",
    "DataObservedSnow.update(d3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def sorted_nicely( l ):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key = alphanum_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "simulation = 'SiteC_3D_3R1A'\n",
    "path = \"/Users/ajc/Core/Projects/ATS-Data/OR-CONDO/simulations/barrow_icewedges/NGEE/SiteC_3D_June10/\"\n",
    "\n",
    "dir_files = os.listdir(path + simulation)\n",
    "Vars = ['temperature-center', 'temperature-right-trough', 'temperature-rim']\n",
    "\n",
    "Files = dict()\n",
    "for var in Vars:\n",
    "    Files_Temp = [f for f in dir_files if f.startswith(var)]\n",
    "    Files[var] = sorted_nicely(Files_Temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DataSim= dict()\n",
    "temp_C = []\n",
    "for var in Vars:\n",
    "    for files in Files[var]:\n",
    "        dat = rd.ReadSingleFile(os.path.join(path+simulation,files))\n",
    "        DataSim[files[:-4]] = np.array(dat['data'])\n",
    "        time = [start_year + t/86400/365. for t in dat['time']]\n",
    "\n",
    "DataSim['Time'] = time\n",
    "#print (DataSim['Time'][251],dat['time'][251])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(DataSim):#.keys():\n",
    "    if 'temperature-right-trough' in key:\n",
    "        K = key.replace('right-',\"\")\n",
    "        DataSim[K] = DataSim[key]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def put_axis(dep, loc=''):\n",
    "    plt.text(2013.2, 246, 'Depth = %s'%(dep),fontsize=11, fontweight='normal')\n",
    "    plt.ylim((245, 285))\n",
    "    plt.yticks(np.linspace(245,285, 5))\n",
    "    plt.xlim((2012.7, 2015))    \n",
    "    \n",
    "\n",
    "DataObserved2012Daily = dict()\n",
    "DataObserved2013Daily = dict()\n",
    "DataObserved2014Daily = dict()\n",
    "DataObserved2015Daily = dict()\n",
    "DataObserved2016Daily = dict()\n",
    "L2012 = len(DataObserved2012['temperature-trough-2cm'])\n",
    "R2012 = L2012%24\n",
    "\n",
    "for key in list(DataObserved2012):#.iteritems():\n",
    "    DataObserved2012Daily[key] = np.reshape(DataObserved2012[key][:-R2012], (-1, 24)).mean(axis=1)\n",
    "\n",
    "L2013 = len(DataObserved2013['temperature-trough-2cm'])\n",
    "R2013 = L2013%24\n",
    "\n",
    "for key in list(DataObserved2013):#.iteritems():\n",
    "    DataObserved2013Daily[key] = np.reshape(DataObserved2013[key][:-R2013], (-1, 24)).mean(axis=1)\n",
    "\n",
    "L2014 = len(DataObserved2014['temperature-trough-2cm'])\n",
    "R2014 = L2014%24\n",
    "\n",
    "for key in list(DataObserved2014):#.iteritems():\n",
    "    DataObserved2014Daily[key] = np.reshape(DataObserved2014[key][:-R2014], (-1, 24)).mean(axis=1)\n",
    "\n",
    "L2015 = len(DataObserved2015['temperature-trough-2cm'])\n",
    "R2015 = L2015%24\n",
    "\n",
    "for key in sorted(list(DataObserved2015)):#.iteritems()):\n",
    "    DataObserved2015Daily[key] = np.reshape(DataObserved2015[key][:-R2015], (-1, 24)).mean(axis=1)\n",
    "\n",
    "#L2016 = len(DataObserved2016['temperature-trough-2cm'])\n",
    "#R2016 = L2016%24\n",
    "\n",
    "#for key, d in sorted(DataObserved2016.iteritems()):\n",
    "#    DataObserved2016Daily[key] = np.reshape(DataObserved2016[key][:-R2016], (-1, 24)).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataObserved2012Daily['time_yr'] = [DataObserved2012Daily['time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSimUpdate = dict()\n",
    "KeysRim = [2,6,11,21,31,46,66,96,146]\n",
    "for key in DataObserved2013Daily.keys():\n",
    "    if key in DataSim.keys() and 'rim' in key:\n",
    "        DataSimUpdate[key] = DataSim[key]\n",
    "    elif 'rim' in key:\n",
    "        index = int(key[key.rfind('-')+1:-2])\n",
    "        if index in KeysRim:\n",
    "            var1 = key[:key.rfind('-')+1] + str(index-1) + 'cm'\n",
    "            var2 = key[:key.rfind('-')+1] + str(index+1) + 'cm'\n",
    "            dat = [0.5*(d1+d2) for d1,d2 in zip(DataSim[var1], DataSim[var2])]\n",
    "            DataSimUpdate[key] = np.array(dat)\n",
    "KeysTrough = [5,10,15,25,35,50,70,100,150]\n",
    "for key in DataObserved2013Daily.keys():\n",
    "    if key in DataSim.keys() and ('center' in key or 'trough' in key):\n",
    "        DataSimUpdate[key] = DataSim[key]\n",
    "    elif 'trough' in key or 'center' in key:\n",
    "        index = int(key[key.rfind('-')+1:-2])\n",
    "        if index in KeysTrough:\n",
    "            var1 = key[:key.rfind('-')+1] + str(index-1) + 'cm'\n",
    "            var2 = key[:key.rfind('-')+1] + str(index+1) + 'cm'\n",
    "            dat = [0.5*(d1+d2) for d1,d2 in zip(DataSim[var1], DataSim[var2])]\n",
    "            DataSimUpdate[key] = np.array(dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = '/Users/ajc/Core/PostProcessData/2019/simulations/barrow-iwp/July16/Temp3D/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDataAll(location = 'center'):\n",
    "    fig, axs = plt.subplots(3,3, figsize=(8,8), facecolor='w', edgecolor='k',gridspec_kw={'width_ratios':[1,1,1]})\n",
    "    fig.subplots_adjust(hspace =.02, wspace=1.02)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    axs = axs.ravel()\n",
    "    Keys = DataObserved2013Daily.keys()\n",
    "    Keys_st = []\n",
    "\n",
    "    if 'rim' in location:\n",
    "        Keys = sorted([key for key in Keys if 'rim' in key])\n",
    "    elif('center' in location):\n",
    "        Keys = sorted([key for key in Keys if 'center' in key])\n",
    "    elif('trough' in location):\n",
    "        Keys = sorted([key for key in Keys if 'trough' in key])\n",
    "    for key in Keys:\n",
    "        l1 = key.rfind('-')\n",
    "        m = key[l1+1:-2]\n",
    "        Keys_st.append(m)\n",
    "        Keys_st = sorted(Keys_st, key=int)\n",
    "    Keys= Keys_st\n",
    "    \n",
    "    #print Keys\n",
    "    #for temp observation in 3D simulations\n",
    "    Z_datum = 4.64311\n",
    "    Z_depths = [Z_datum - int(k)/100. for k in Keys]\n",
    "    #print Z_depths\n",
    "    Keys = np.concatenate((Keys[:4],Keys[5::2]))\n",
    "    #print Keys\n",
    "    for i in range(1,10):\n",
    "        x='33'+str(i)\n",
    "        var = 'temperature-%s-'%location + Keys[i] + 'cm'\n",
    "        plt.subplot(x)\n",
    "        #print var\n",
    "        if var in DataObserved2012Daily.keys():\n",
    "            plt.plot(DataObserved2012Daily['time'],  DataObserved2012Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2013Daily['time'],  DataObserved2013Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2014Daily['time'],  DataObserved2014Daily[var],'r',linestyle='-')\n",
    "        if i ==9 and var in DataObserved2015Daily.keys():\n",
    "            plt.plot(DataObserved2015Daily['time'],  DataObserved2015Daily[var],'r',linestyle='-',label='Observed')\n",
    "        elif var in DataObserved2015Daily.keys():\n",
    "            plt.plot(DataObserved2015Daily['time'],  DataObserved2015Daily[var],'r',linestyle='-')\n",
    "        \n",
    "        if i == 9:\n",
    "            plt.plot(DataSim['Time'][::1], DataSimUpdate[var][::1],'k',linestyle='--',label='Simulated')\n",
    "        else:\n",
    "            plt.plot(DataSim['Time'][::1], DataSimUpdate[var][::1],'k',linestyle='--')\n",
    "        plt.axhline(y=273.15,linestyle='--',color='g')\n",
    "        put_axis(Keys[i] + 'cm', location)\n",
    "    \n",
    "    plt.legend(loc='upper right', fontsize=10, ncol=3, bbox_to_anchor=(0.7,- 0.32, .1, .1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outfile+'%s-temp-%s-2020.pdf'%(simulation, location), bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_at_depths(location = 'center'):\n",
    "    fig, axs = plt.subplots(3,3, figsize=(8,8), facecolor='w', edgecolor='k',gridspec_kw={'width_ratios':[1,1,1]})\n",
    "    fig.subplots_adjust(hspace =.02, wspace=1.02)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    axs = axs.ravel()\n",
    "    Keys = DataObserved2013Daily.keys()\n",
    "    Keys_st = []\n",
    "\n",
    "    Vars = ['temperature-trough-5cm','temperature-trough-50cm','temperature-trough-150cm']\n",
    "    for i in range(0,3):\n",
    "        x='33'+str(3*i+1)\n",
    "        plt.subplot(x)\n",
    "        var = Vars[i]\n",
    "        plt.plot(DataObserved2012Daily['time'],  DataObserved2012Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2013Daily['time'],  DataObserved2013Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2014Daily['time'],  DataObserved2014Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2015Daily['time'],  DataObserved2015Daily[var],'r',linestyle='-')#,label='Observed')\n",
    "\n",
    "        \n",
    "        plt.plot(DataSim['Time'][::1], DataSimUpdate[var][::1],'k',linestyle='--',label='Simulated')\n",
    "        \n",
    "        plt.axhline(y=273.15,linestyle='--',color='g')\n",
    "        put_axis(var[var.rfind('-')+1:-2] + ' cm', loc='Trough')\n",
    "        plt.ylabel('Soil temperature [K]')\n",
    "        if i == 0:\n",
    "            plt.title('Trough',fontsize=12, fontweight='bold')\n",
    "            \n",
    "    Vars = ['temperature-center-5cm','temperature-center-50cm','temperature-center-150cm']\n",
    "    for i in range(0,3):\n",
    "        x='33'+str(3*i+2)\n",
    "        plt.subplot(x)\n",
    "        var = Vars[i]\n",
    "        plt.plot(DataObserved2012Daily['time'],  DataObserved2012Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2013Daily['time'],  DataObserved2013Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2014Daily['time'],  DataObserved2014Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2015Daily['time'],  DataObserved2015Daily[var],'r',linestyle='-')#,label='Observed')\n",
    "        \n",
    "        plt.plot(DataSim['Time'][::1], DataSimUpdate[var][::1],'k',linestyle='--')#,label='Simulated')\n",
    "        if i == 0:\n",
    "            plt.title('Center',fontsize=12, fontweight='bold')\n",
    "        plt.axhline(y=273.15,linestyle='--',color='g')\n",
    "        put_axis(var[var.rfind('-')+1:-2] + ' cm', loc='Center')\n",
    "        \n",
    "    Vars = ['temperature-rim-5cm', 'temperature-rim-6cm','temperature-rim-45cm','temperature-rim-46cm','temperature-rim-50cm','temperature-rim-146cm','temperature-rim-150cm']\n",
    "    for i in range(0,3):\n",
    "        x='33'+str(3*i+3)\n",
    "        plt.subplot(x)\n",
    "        \n",
    "        if i == 0:\n",
    "            var = Vars[0]\n",
    "            plt.plot(DataObserved2012Daily['time'],  DataObserved2012Daily[Vars[0]],'r',linestyle='-')\n",
    "            plt.plot(DataObserved2013Daily['time'],  DataObserved2013Daily[Vars[1]],'r',linestyle='-')\n",
    "            plt.plot(DataObserved2014Daily['time'],  DataObserved2014Daily[Vars[1]],'r',linestyle='-')\n",
    "            plt.plot(DataObserved2015Daily['time'],  DataObserved2015Daily[Vars[0]],'r',linestyle='-')#,label='Observed')\n",
    "            plt.plot(DataSim['Time'][::1], DataSimUpdate[Vars[1]][::1],'k',linestyle='--')#,label='Simulated')\n",
    "        elif i == 1:\n",
    "            var = Vars[3]\n",
    "            plt.plot(DataObserved2013Daily['time'],  DataObserved2013Daily[Vars[3]],'r',linestyle='-')\n",
    "            plt.plot(DataObserved2014Daily['time'],  DataObserved2014Daily[Vars[3]],'r',linestyle='-')\n",
    "            plt.plot(DataSim['Time'][::1], DataSimUpdate[Vars[3]][::1],'k',linestyle='--')#,label='Simulated')\n",
    "        elif i == 2:\n",
    "            var = Vars[-2]\n",
    "            plt.plot(DataObserved2012Daily['time'],  DataObserved2012Daily[Vars[-1]],'r',linestyle='-')\n",
    "            plt.plot(DataObserved2013Daily['time'],  DataObserved2013Daily[Vars[-2]],'r',linestyle='-')\n",
    "            plt.plot(DataObserved2014Daily['time'],  DataObserved2014Daily[Vars[-2]],'r',linestyle='-',label='Observed')\n",
    "            plt.plot(DataSim['Time'][::1], DataSimUpdate[Vars[-2]][::1],'k',linestyle='--',label='Simulated')\n",
    "        \n",
    "        plt.axhline(y=273.15,linestyle='--',color='g')\n",
    "        put_axis(var[var.rfind('-')+1:-2] + ' cm', loc='Rim')\n",
    "        if i == 0:\n",
    "            plt.title('Rim',fontsize=12, fontweight='bold')\n",
    "        \n",
    "    plt.legend(loc='upper right', fontsize=10, ncol=3, bbox_to_anchor=(0.7,- 0.32, .1, .1))\n",
    "    #plt.tight_layout()\n",
    "    plt.savefig(outfile+'%s-temp-%s-2020.pdf'%(simulation, location), bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotDataAll(location='rim')\n",
    "plot_at_depths()\n",
    "#DataObserved2012Daily.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compure RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "#RMSD = sqrt(mean_squared_error(testing_y, prediction))\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start(sim_dat, ob_dat):\n",
    "    start = 0\n",
    "    for t in sim_dat:\n",
    "            if t<=ob_dat:\n",
    "                start = start + 1\n",
    "            else:\n",
    "                break\n",
    "    return start\n",
    "    \n",
    "def computer_rmse_at_depths(Vars):\n",
    "    #Vars = ['temperature-trough-5cm','temperature-trough-50cm','temperature-trough-150cm']\n",
    "    X, Y = [], []\n",
    "    Trough = []\n",
    "    Count = []\n",
    "    Year = ['2012', '2013','2014']\n",
    "    for i, var in enumerate(Vars):\n",
    "        L = DataObserved2012Daily[var].shape[0]\n",
    "        \n",
    "        d_trough = 0\n",
    "        d1_trough= 0\n",
    "        c_trough = 0\n",
    "        for j in range(3):\n",
    "            \n",
    "            if j == 0:\n",
    "                t_0 = DataObserved2012Daily['time'][0]\n",
    "                data = DataObserved2012Daily[var]\n",
    "            elif (j==1):\n",
    "                t_0 = DataObserved2013Daily['time'][0]\n",
    "                data = DataObserved2013Daily[var]\n",
    "            elif (j==2):\n",
    "                t_0 = DataObserved2014Daily['time'][0]\n",
    "                data = DataObserved2014Daily[var]\n",
    "            \n",
    "            start = get_start(DataSim['Time'], t_0)\n",
    "            print (Year[j],var, start, DataSim['Time'][start],t_0)\n",
    "        \n",
    "            for x1,x2,y in zip(DataSimUpdate[var][start:],DataSimUpdate[var][start+1:],data):\n",
    "                x = (x1 + x2)/2.\n",
    "    \n",
    "                if not np.isnan(y):\n",
    "                    d_trough = d_trough  + (x-y)**2\n",
    "                    d1_trough = d1_trough + (x-y)\n",
    "                    X.append(x)\n",
    "                    Y.append(y)\n",
    "                    c_trough = c_trough + 1.\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(X,Y)\n",
    "        print (np.sqrt(d_trough/c_trough), d1_trough/c_trough,r_value**2, c_trough)\n",
    "        \n",
    "        print ('-------------------')\n",
    "    \n",
    "def computer_rmse_at_depths_rims():\n",
    "    Vars = ['temperature-rim-5cm', 'temperature-rim-6cm','temperature-rim-45cm','temperature-rim-46cm',\n",
    "            'temperature-rim-50cm','temperature-rim-146cm','temperature-rim-150cm']\n",
    "    Vars_ = ['temperature-rim-6cm','temperature-rim-46cm','temperature-rim-146cm']\n",
    "    X, Y = [], []\n",
    "    Trough = []\n",
    "    Count = []\n",
    "    Year = ['2012', '2013','2014']\n",
    "    for i, var1 in enumerate(Vars_):\n",
    "        #L = DataObserved2012Daily[var].shape[0]\n",
    "        \n",
    "        d_trough = 0\n",
    "        d1_trough= 0\n",
    "        c_trough = 0\n",
    "        \n",
    "        for j in range(3):\n",
    "            if i ==0 and j ==0:\n",
    "                var = Vars[0]\n",
    "            elif i ==0 and j>=1:\n",
    "                var = Vars[1]\n",
    "            elif i ==1:\n",
    "                var = Vars[3]\n",
    "            elif i == 2 and j ==0:\n",
    "                var = Vars[-1]\n",
    "            else:\n",
    "                var = Vars[-2]\n",
    "            \n",
    "            if j == 0 and i != 1:\n",
    "                print (j,i)\n",
    "                t_0 = DataObserved2012Daily['time'][0]\n",
    "                data = DataObserved2012Daily[var]\n",
    "            elif (j==1):\n",
    "                t_0 = DataObserved2013Daily['time'][0]\n",
    "                data = DataObserved2013Daily[var]\n",
    "            elif (j==2):\n",
    "                t_0 = DataObserved2014Daily['time'][0]\n",
    "                data = DataObserved2014Daily[var]\n",
    "            \n",
    "            start = get_start(DataSim['Time'], t_0)\n",
    "            print (Year[j],var1, start, DataSim['Time'][start],t_0)\n",
    "        \n",
    "            for x1,x2,y in zip(DataSimUpdate[var1][start:],DataSimUpdate[var1][start+1:],data):\n",
    "                x = (x1 + x2)/2.\n",
    "    \n",
    "                if not np.isnan(y):\n",
    "                    d_trough = d_trough  + (x-y)**2\n",
    "                    d1_trough = d1_trough + (x-y)\n",
    "                    X.append(x)\n",
    "                    Y.append(y)\n",
    "                    c_trough = c_trough + 1.\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(X,Y)\n",
    "        print (np.sqrt(d_trough/c_trough), d1_trough/c_trough,r_value**2, c_trough)\n",
    "        \n",
    "        print ('-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer_rmse_at_depths(Vars = ['temperature-trough-5cm','temperature-trough-50cm','temperature-trough-150cm'])\n",
    "print ('*****************************')\n",
    "computer_rmse_at_depths(Vars = ['temperature-center-5cm','temperature-center-50cm','temperature-center-150cm'])\n",
    "print ('*****************************')\n",
    "computer_rmse_at_depths_rims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (DataSimUpdate.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "385 1.9116673441370198 0.9594680204438512\n",
    "385 1.572722238339265 0.957940460064878\n",
    "385 1.0740584820090064 0.9572889925757113\n",
    "----------------------------\n",
    "364 1.6671495941692096 0.9543868378970013\n",
    "364 0.7857730834047848 0.964123552609639\n",
    "364 0.6971167923279932 0.9680571190832975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "        #Trough.append(d_trough)\n",
    "        L = DataObserved2013Daily[var].shape[0]\n",
    "        \n",
    "        #d_trough = 0\n",
    "        #d1_trough= 0\n",
    "        c_trough2013 = 1\n",
    "        start = get_start(DataSim['Time'], DataObserved2013Daily['time'][0])\n",
    "        print ('2013: ',var, start, DataSim['Time'][start],DataObserved2013Daily['time'][0],DataObserved2013Daily['time'][-1])\n",
    "        \n",
    "        for x1,x2,y in zip(DataSimUpdate[var][start:],DataSimUpdate[var][start+1:],DataObserved2013Daily[var]):\n",
    "            x = (x1 + x2)/2.\n",
    "    \n",
    "            if not np.isnan(y):\n",
    "                d_trough = d_trough  + (x-y)**2\n",
    "                d1_trough = d1_trough + (x-y)\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "                c_trough2013 = c_trough2013 + 1.\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(X,Y)\n",
    "        print ('2013 ',L,d_trough, c_trough2013, np.sqrt(d_trough/c_trough2013), d1_trough/c_trough2013,r_value**2)\n",
    "        \n",
    "        \n",
    "        L = DataObserved2013Daily[var].shape[0]\n",
    "        \n",
    "        #d_trough = 0\n",
    "        #d1_trough= 0\n",
    "        c_trough2014 = 1\n",
    "        start = get_start(DataSim['Time'], DataObserved2014Daily['time'][0])\n",
    "        \n",
    "        print ('2014: ',var, start, DataSim['Time'][1003],DataObserved2014Daily['time'][0],DataObserved2014Daily['time'][91])\n",
    "        \n",
    "        for x1,x2,y in zip(DataSimUpdate[var][start:],DataSimUpdate[var][start+1:],DataObserved2014Daily[var][:91]):\n",
    "            x = (x1 + x2)/2.\n",
    "    \n",
    "            if not np.isnan(y):\n",
    "                d_trough = d_trough  + (x-y)**2\n",
    "                d1_trough = d1_trough + (x-y)\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "                c_trough2014 = c_trough2014 + 1.\n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(X,Y)\n",
    "        print ('2014',L,d_trough, c_trough2014, np.sqrt(d_trough/c_trough2014), d1_trough/c_trough2014,r_value**2)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "print ('----------------------------')\n",
    "    Vars = ['temperature-center-5cm','temperature-center-50cm','temperature-center-150cm']\n",
    "    X, Y = [], []\n",
    "    for i, var in enumerate(Vars):\n",
    "        \n",
    "        L = DataObserved2013Daily[var].shape[0]\n",
    "        d_center = 0\n",
    "        d1_center = 0\n",
    "        count_center = 0\n",
    "        print (var, DataSim['Time'][638],DataObserved2013Daily['time'][0],DataObserved2013Daily['time'][-1])\n",
    "        for x1,x2,y in zip(DataSimUpdate[var][638:],DataSimUpdate[var][639:],DataObserved2013Daily[var]):\n",
    "            x = (x1 + x2)/2.\n",
    "            if not np.isnan(y):\n",
    "                d_center = d_center  + (x-y)**2\n",
    "                d1_center = d1_center + (x-y)\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "                count_center = count_center + 1.\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(X,Y)\n",
    "        print (L,np.sqrt(d_center/count_center), d1_center/count_center, r_value**2)\n",
    "    \n",
    "    print ('----------------------------')\n",
    "    Vars = ['temperature-rim-5cm', 'temperature-rim-6cm','temperature-rim-45cm','temperature-rim-46cm',\n",
    "            'temperature-rim-50cm','temperature-rim-146cm','temperature-rim-150cm']\n",
    "    \n",
    "    X, Y = [], []\n",
    "    for i, var in enumerate(Vars):\n",
    "        \n",
    "        L = DataObserved2014Daily[Vars[0]].shape[0]\n",
    "        d_rim = 0\n",
    "        d1_rim = 0\n",
    "        count_rim = 0\n",
    "        print ('Rim', DataSim['Time'][800],DataObserved2014Daily['time'][0],DataObserved2014Daily['time'][-1])\n",
    "        for x1,x2,y in zip(DataSimUpdate[var][638:],DataSimUpdate[var][639:],DataObserved2014Daily[var]):\n",
    "            x = (x1 + x2)/2.\n",
    "            if not np.isnan(y):\n",
    "                d_rim = d_rim  + (x-y)**2\n",
    "                d1_rim = d1_rim + (x-y)\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "                count_rim = count_rim + 1.\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(X,Y)\n",
    "        print (L,np.sqrt(d_rim/count_rim), d1_rim/count_rim, r_value**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellid = 0\n",
    "\n",
    "surfdata = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-precipitation_rain', cellid=cellid)\n",
    "plt.plot(surfdata['surface-precipitation_rain'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vars = ['precipitation_rain', 'thermal_conductivity', 'ponded_depth']\n",
    "vars = ['surface-' + v for v in vars]\n",
    "fig, axs = plt.subplots(3,3, figsize=(8,8), facecolor='w', edgecolor='k',gridspec_kw={'width_ratios':[1,1,1]})\n",
    "fig.subplots_adjust(hspace =.02, wspace=1.02)\n",
    "plt.tight_layout()\n",
    "axs = axs.ravel()\n",
    "for i in range(1,4):\n",
    "    x='33'+str(i)\n",
    "    plt.subplot(x)\n",
    "    snow_depth = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', vars[i-1], cellid=cellid)\n",
    "    plt.plot(DataSim['time_d'],snow_depth[vars[i-1]],'-')\n",
    "    plt.ylabel('%s'%vars[i-1])\n",
    "    plt.xlim(4,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['snow-age', 'snow-depth', 'snow-conductivity','snow-density','snow-precipitation', 'snow-swe', 'surface-air_temperature', 'surface-temperature', 'snow-temperature']\n",
    "\n",
    "fig, axs = plt.subplots(3,3, figsize=(8,8), facecolor='w', edgecolor='k',gridspec_kw={'width_ratios':[1,1,1]})\n",
    "fig.subplots_adjust(hspace =.02, wspace=1.02)\n",
    "plt.tight_layout()\n",
    "axs = axs.ravel()\n",
    "SimTime  = np.array([t/365.25 for t in DataSim['time_d']])\n",
    "SnowData = dict()\n",
    "snow_annual = 0\n",
    "snow_time = 0\n",
    "snow_fall = []\n",
    "for i in range(1,10):\n",
    "    x='33'+str(i)\n",
    "    plt.subplot(x)\n",
    "    if 'snow' in vars[i-1]:\n",
    "        snow_depth = rd.GetSurfVarFromVis(infile_simulated+'/visdump_snow_data.h5', vars[i-1], cellid=cellid)\n",
    "    else:\n",
    "        snow_depth = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', vars[i-1], cellid=cellid)\n",
    "            \n",
    "    SnowData.update(snow_depth)\n",
    "    if 'precip' in vars[i-1]:\n",
    "        snow_annual = np.reshape(SnowData['snow-precipitation'][:5*365],(365,5)).sum(axis=0)\n",
    "        snow_time = np.reshape(SimTime[:5*365],(5,365)).mean(axis=1)\n",
    "        sum1, sum2, sum3 = 0,0,0\n",
    "        for j,sn in enumerate(SimTime):\n",
    "            if sn >2.5 and sn <3.5:\n",
    "                sum1 = sum1 + SnowData['snow-precipitation'][j]\n",
    "            if sn >3.5 and sn <4.5:\n",
    "                sum2 = sum2 + SnowData['snow-precipitation'][j]\n",
    "            if sn >4.5 and sn <5.5:\n",
    "                sum3 = sum3 + SnowData['snow-precipitation'][j]\n",
    "                \n",
    "        snow_fall = [sum1, sum2, sum3]\n",
    "        snow_time = [3.0,4.0, 5.0]\n",
    "        print snow_fall, snow_time\n",
    "        plt.ylim(0,2.5e-7)\n",
    "        plt.plot(SimTime,snow_depth[vars[i-1]],'-')\n",
    "        plt.ylabel('%s'%vars[i-1])\n",
    "        ax0  = plt.twinx()\n",
    "        ax0.plot(snow_time,snow_fall,'*', color='g')\n",
    "        ax0.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "        ax0.set_ylim(0,1.0e-5)\n",
    "        ax0.set_ylabel('Mean snow precip')\n",
    "        \n",
    "        \n",
    "    if not 'precip' in vars[i-1]:\n",
    "        plt.plot(SimTime,snow_depth[vars[i-1]],'-', color='k')\n",
    "        plt.ylabel('%s'%vars[i-1])\n",
    "    if 'temperature' in vars[i-1]:\n",
    "        plt.axhline(y=273.15,color ='c',linestyle='--')\n",
    "    if 'snow-depth' in vars[i-1]:\n",
    "        plt.plot(DataObservedSnow['snow_time_Center'], DataObservedSnow['snow_depth_Center'],'.',color='r',markersize=2,label='Center')\n",
    "        #plt.plot(DataObservedSnow['snow_time_Rim'], DataObservedSnow['snow_depth_Rim'],'.',color='g',markersize=2,label='Rim')\n",
    "        #plt.plot(DataObservedSnow['snow_time_Trough'], DataObservedSnow['snow_depth_Trough'],color='b',markersize=2,label='Trough')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.xlim(2.5,5.5)\n",
    "    \n",
    "\n",
    "      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_depth_T = rd.GetSurfVarFromVis(infile_simulated+'/visdump_snow_data.h5', 'snow-depth', cellid=0)\n",
    "snow_depth_R = rd.GetSurfVarFromVis(infile_simulated+'/visdump_snow_data.h5', 'snow-depth', cellid=10)\n",
    "snow_depth_C = rd.GetSurfVarFromVis(infile_simulated+'/visdump_snow_data.h5', 'snow-depth', cellid=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_T = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-elevation', cellid=0)\n",
    "Z_R = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-elevation', cellid=10)\n",
    "Z_C = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-elevation', cellid=37)\n",
    "print Z_T['surface-elevation'][0], Z_R['surface-elevation'][0], Z_C['surface-elevation'][0]\n",
    "\n",
    "surf_pd_T = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-ponded_depth', cellid=0)\n",
    "surf_pd_R = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-ponded_depth', cellid=10)\n",
    "surf_pd_C = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-ponded_depth', cellid=37)\n",
    "print surf_pd_T['surface-ponded_depth'][0], surf_pd_R['surface-ponded_depth'][0], surf_pd_C['surface-ponded_depth'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['snow-depth']\n",
    "\n",
    "fig, axs = plt.subplots(3,1, figsize=(9,4), facecolor='w', edgecolor='k',gridspec_kw={'width_ratios':[1]})\n",
    "fig.subplots_adjust(hspace =.02, wspace=0.25)\n",
    "plt.tight_layout()\n",
    "axs = axs.ravel()\n",
    "SimTime  = np.array([t/365.25 for t in DataSim['time_d']])\n",
    "SnowData = dict()\n",
    "\n",
    "Elev = 1\n",
    "pd = 1\n",
    "plt.subplot(131)\n",
    "snow_depth_Tr = [ pd*d1 + Z_T['surface-elevation'][0]*Elev + d2 for d1,d2 in zip(surf_pd_T['surface-ponded_depth'],snow_depth_T['snow-depth']) ]\n",
    "DataObservedSnowT = [Z_T['surface-elevation'][0]*Elev + d for d in DataObservedSnow['snow_depth_Trough'] ]\n",
    "plt.plot(SimTime, snow_depth_Tr,marker='*',color='k',label='Sim Trough')\n",
    "plt.plot(DataObservedSnow['snow_time_Trough'], DataObservedSnowT,'.',color='r',label='Observed Trough')\n",
    "plt.legend(loc='upper left',fontsize=6)\n",
    "plt.xlim(2.5,5.5)\n",
    "if Elev > 0:\n",
    "    plt.ylim(4.9,5.8)\n",
    "else:\n",
    "    plt.ylim(0,0.7)\n",
    "plt.ylabel('Snow depth [m]')\n",
    "plt.xlabel('Time [yr]')\n",
    "\n",
    "plt.subplot(132)\n",
    "snow_depth_Ri = [ pd*d1 + Z_R['surface-elevation'][0]*Elev + d2 for d1,d2 in zip(surf_pd_R['surface-ponded_depth'],snow_depth_R['snow-depth']) ]\n",
    "DataObservedSnowR = [Z_R['surface-elevation'][0]*Elev + d for d in DataObservedSnow['snow_depth_Rim'] ]\n",
    "plt.plot(SimTime, snow_depth_Ri,color='k',marker='*',label='Sim Rim')\n",
    "plt.plot(DataObservedSnow['snow_time_Rim'], DataObservedSnowR,'.',color='r',label='Observed Rim')\n",
    "plt.legend(loc='upper left',fontsize=6)\n",
    "plt.xlim(2.5,5.5)\n",
    "if Elev > 0:\n",
    "    plt.ylim(4.9,5.8)\n",
    "else:\n",
    "    plt.ylim(0,0.7)\n",
    "\n",
    "plt.ylabel('Snow depth [m]')\n",
    "plt.xlabel('Time [yr]')\n",
    "\n",
    "plt.subplot(133)\n",
    "snow_depth_Ce = [ pd*d1 + Z_C['surface-elevation'][0]*Elev + d2 for d1,d2 in zip(surf_pd_C['surface-ponded_depth'],snow_depth_C['snow-depth']) ]\n",
    "DataObservedSnowC = [Z_C['surface-elevation'][0]*Elev + d for d in DataObservedSnow['snow_depth_Center'] ]\n",
    "plt.plot(SimTime, snow_depth_Ce,color='k',marker='*',label='Sim Center')\n",
    "plt.plot(DataObservedSnow['snow_time_Center'], DataObservedSnowC,'.',color='r',label='Observed Center')\n",
    "plt.ylabel('Snow depth [m]')\n",
    "plt.xlabel('Time [yr]')\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left',fontsize=6)\n",
    "\n",
    "plt.xlim(2.5,5.5)\n",
    "if Elev > 0:\n",
    "    plt.ylim(4.9,5.8)\n",
    "else:\n",
    "    plt.ylim(0,0.7)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(outfileSnow+'%s-snow.pdf'%(simulation), bbox_inches='tight', dpi=100)\n",
    "      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['snow-depth']\n",
    "\n",
    "fig, axs = plt.subplots(3,1, figsize=(9,4), facecolor='w', edgecolor='k',gridspec_kw={'width_ratios':[1]})\n",
    "fig.subplots_adjust(hspace =.02, wspace=0.25)\n",
    "plt.tight_layout()\n",
    "axs = axs.ravel()\n",
    "#SimTime  = np.array([t/365.25 for t in DataSim['time_d']])\n",
    "SnowData = dict()\n",
    "\n",
    "Elev = 0\n",
    "plt.subplot(131)\n",
    "snow_depth_Tr = [ Z_T['surface-elevation'][0]*Elev + d for d in snow_depth_T['snow-depth'] ]\n",
    "DataObservedSnowT = [Z_T['surface-elevation'][0]*Elev + d for d in DataObservedSnow['snow_depth_Trough'] ]\n",
    "plt.plot(snow_depth_Tr,marker='*',color='k',label='Sim Trough')\n",
    "#plt.plot(DataObservedSnow['snow_time_Trough'], DataObservedSnowT,'.',color='r',label='Observed Trough')\n",
    "plt.legend(loc='upper left',fontsize=6)\n",
    "#plt.xlim(2.5,5.5)\n",
    "if Elev > 0:\n",
    "    plt.ylim(4.9,5.8)\n",
    "else:\n",
    "    plt.ylim(0,0.7)\n",
    "plt.ylabel('Snow depth [m]')\n",
    "plt.xlabel('Time [yr]')\n",
    "\n",
    "plt.subplot(132)\n",
    "snow_depth_Ri = [ Z_R['surface-elevation'][0]*Elev + d for d in snow_depth_R['snow-depth'] ]\n",
    "DataObservedSnowR = [Z_R['surface-elevation'][0]*Elev + d for d in DataObservedSnow['snow_depth_Rim'] ]\n",
    "plt.plot(snow_depth_Ri,color='k',marker='*',label='Sim Rim')\n",
    "#plt.plot(DataObservedSnow['snow_time_Rim'], DataObservedSnowR,'.',color='r',label='Observed Rim')\n",
    "plt.legend(loc='upper left',fontsize=6)\n",
    "#plt.xlim(2.5,5.5)\n",
    "if Elev > 0:\n",
    "    plt.ylim(4.9,5.8)\n",
    "else:\n",
    "    plt.ylim(0,0.7)\n",
    "\n",
    "plt.ylabel('Snow depth [m]')\n",
    "plt.xlabel('Time [yr]')\n",
    "\n",
    "plt.subplot(133)\n",
    "snow_depth_Ce = [ Z_C['surface-elevation'][0]*Elev + d for d in snow_depth_C['snow-depth'] ]\n",
    "DataObservedSnowC = [Z_C['surface-elevation'][0]*Elev + d for d in DataObservedSnow['snow_depth_Center'] ]\n",
    "plt.plot(snow_depth_Ce,color='k',marker='*',label='Sim Center')\n",
    "#plt.plot(DataObservedSnow['snow_time_Center'], DataObservedSnowC,'.',color='r',label='Observed Center')\n",
    "plt.ylabel('Snow depth [m]')\n",
    "plt.xlabel('Time [yr]')\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left',fontsize=6)\n",
    "\n",
    "#plt.xlim(2.5,5.5)\n",
    "if Elev > 0:\n",
    "    plt.ylim(4.9,5.8)\n",
    "else:\n",
    "    plt.ylim(0,0.7)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(outfileSnow+'%s-snow.pdf'%(simulation), bbox_inches='tight', dpi=100)\n",
    "      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
