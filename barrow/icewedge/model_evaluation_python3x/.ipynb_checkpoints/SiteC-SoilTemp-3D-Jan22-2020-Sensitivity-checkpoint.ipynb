{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "sys.path.append('/Users/ajc/Desktop/SimDataInputs/ats-repo/ats/tools/utils/')\n",
    "sys.path.append('/Users/ajc/Projects/ATS-Data/OR-CONDO/mytests-orhydra/PyScript')\n",
    "import readdata as rd\n",
    "import parse_ats, transect_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = '/Users/ajc/AllPostProcessData/BarrowTransect/NGEE/Temperature-SiteC/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"     \\nfor c in data5.columns:\\n    k = -100\\n    if 'trough' in c or 'center' in c or 'rim' in c:\\n        k = int(float(c[6:10])*100)\\n        dat = np.array([ x + 273.15  for x in data5[c]])\\n        d = np.array([dat[i-1] if np.isnan(x) else x for i,x in enumerate(dat)])\\n    if 'trough' in c:\\n        DataObserved2016['temperature-trough-%scm'%k] = d\\n    elif 'center' in c and not 'off' in c :\\n        DataObserved2016['temperature-center-%scm'%k] = d\\n    elif 'rim' in c and 'rim2' not in c:\\n        if k > 2:\\n            k = k + 1*0\\n        DataObserved2016['temperature-rim-%scm'%k] = d\\n        \\n        \\n    if 'Time' in c:\\n        time1 = [pd.to_datetime(data5['Timestamp'])]\\n        time = [(t - time_origin).dt.total_seconds()/86400 for t in time1]\\n        Time = np.array([start_year +t/365. for t in time[0]])\\n        #Time = np.array([t for t in time[0]])\\n        DataObserved2016['time'] = np.array(Time)\\n        DataObserved2016['time_yr'] = [2010 + t/365 for t in Time]\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile = '/Users/ajc/Desktop/SimDataInputs/barrow-polygon-data/Vladimir-Data/Area_C/'\n",
    "save = False\n",
    "\n",
    "dataset1= 'NGEE_BRW_C_2012-09-09_2013-09-30_Thermal_Transect_and_Borehole.csv' # 2012-13\n",
    "dataset2= 'NGEE_BRW_C_2013-10-01_2014-09-30_Thermal_Transect_and_Borehole.csv' # 2013-14\n",
    "dataset3= 'NGEE_BRW_C_2014-10-01_2015-09-30_Thermal_Transect_and_Borehole.csv' # 2014-15\n",
    "dataset4= 'NGEE_BRW_C_2015-10-01_2016-09-30_Thermal_Transect_and_Borehole.csv' # 2015-16\n",
    "#dataset5= 'NGEE_BRW_C_2016-10-01_2017-09-30_Thermal_Transect_and_Borehole.csv' # 2014-15\n",
    "\n",
    "time_origin = datetime.datetime(2010,1,1,0,0,0)\n",
    "\n",
    "infile_observed1 = infile + dataset1\n",
    "infile_observed2 = infile + dataset2\n",
    "infile_observed3 = infile + dataset3\n",
    "infile_observed4 = infile + dataset4\n",
    "#infile_observed5 = infile + dataset5\n",
    "data1 = pd.read_csv(infile_observed1, skiprows=5)\n",
    "data2 = pd.read_csv(infile_observed2, skiprows=5)\n",
    "data3 = pd.read_csv(infile_observed3, skiprows=5)\n",
    "data4 = pd.read_csv(infile_observed4, skiprows=5)\n",
    "#data5 = pd.read_csv(infile_observed5, skiprows=5)\n",
    "\n",
    "DataObserved2012 = dict()\n",
    "DataObserved2013 = dict()\n",
    "DataObserved2014 = dict()\n",
    "DataObserved2015 = dict()\n",
    "DataObserved2016 = dict()\n",
    "start_year = 2010\n",
    "for c in data1.columns:\n",
    "    k = -100\n",
    "    if 'trough' in c or 'center' in c or 'rim' in c:\n",
    "        k = int(float(c[6:10])*100)\n",
    "        dat = np.array([ x + 273.15  for x in data1[c]])\n",
    "        d = np.array([dat[i-1] if np.isnan(x) else x for i,x in enumerate(dat)])\n",
    "        \n",
    "    if 'trough' in c:\n",
    "        DataObserved2012['temperature-trough-%scm'%k] = d\n",
    "    elif 'center' in c and not 'off' in c :\n",
    "        DataObserved2012['temperature-center-%scm'%k] = d\n",
    "    elif 'rim' in c and 'rim2' not in c:\n",
    "        if k > 2:\n",
    "            k = k + 1*0\n",
    "        DataObserved2012['temperature-rim-%scm'%k] = d\n",
    "        \n",
    "    if 'Time' in c:\n",
    "        time1 = [pd.to_datetime(data1['Timestamp'])]\n",
    "        time = [(t - time_origin).dt.total_seconds()/86400 for t in time1]\n",
    "        Time = np.array([start_year + t/365. for t in time[0]])\n",
    "        #Time = np.array([t for t in time[0]])\n",
    "        DataObserved2012['time'] = np.array(Time)\n",
    "        DataObserved2012['time_yr'] = [2010 + t/365 for t in Time]\n",
    "\n",
    "for c in data2.columns:\n",
    "    k = -100\n",
    "    if 'trough' in c or 'center' in c or 'rim' in c:\n",
    "        k = int(float(c[6:10])*100)\n",
    "        dat = np.array([ x + 273.15  for x in data2[c]])\n",
    "        d = np.array([dat[i-1] if np.isnan(x) else x for i,x in enumerate(dat)])\n",
    "    if 'trough' in c:\n",
    "        DataObserved2013['temperature-trough-%scm'%k] = d\n",
    "    elif 'center' in c and not 'off' in c :\n",
    "        DataObserved2013['temperature-center-%scm'%k] = d\n",
    "    elif 'rim' in c and 'rim2' not in c:\n",
    "        DataObserved2013['temperature-rim-%scm'%k] = d\n",
    "    if 'Time' in c:\n",
    "        time1 = [pd.to_datetime(data2['Timestamp'])]\n",
    "        time = [(t - time_origin).dt.total_seconds()/86400 for t in time1]\n",
    "        Time = np.array([start_year +t/365. for t in time[0]])\n",
    "        #Time = np.array([t for t in time[0]])\n",
    "        DataObserved2013['time'] = np.array(Time)\n",
    "        DataObserved2013['time_yr'] = [2010 + t/365 for t in Time]\n",
    "    \n",
    "for c in data3.columns:\n",
    "    k = -100\n",
    "    if 'trough' in c or 'center' in c or 'rim' in c:\n",
    "        k = int(float(c[6:10])*100)\n",
    "        dat = np.array([ x + 273.15  for x in data3[c]])\n",
    "        d = np.array([dat[i-1] if np.isnan(x) else x for i,x in enumerate(dat)])\n",
    "    if 'trough' in c:\n",
    "        DataObserved2014['temperature-trough-%scm'%k] = d\n",
    "    elif 'center' in c and not 'off' in c :\n",
    "        DataObserved2014['temperature-center-%scm'%k] = d\n",
    "    elif 'rim' in c and 'rim2' not in c:\n",
    "        DataObserved2014['temperature-rim-%scm'%k] = d\n",
    "    if 'Time' in c:\n",
    "        time1 = [pd.to_datetime(data3['Timestamp'])]\n",
    "        time = [(t - time_origin).dt.total_seconds()/86400 for t in time1]\n",
    "        Time = np.array([start_year +t/365. for t in time[0]])\n",
    "        #Time = np.array([t for t in time[0]])\n",
    "        DataObserved2014['time'] = np.array(Time)\n",
    "        DataObserved2014['time_yr'] = [2010 + t/365 for t in Time]\n",
    "\n",
    "for c in data4.columns:\n",
    "    k = -100\n",
    "    if 'trough' in c or 'center' in c or 'rim' in c:\n",
    "        k = int(float(c[6:10])*100)\n",
    "        dat = np.array([ x + 273.15  for x in data4[c]])\n",
    "        d = np.array([dat[i-1] if np.isnan(x) else x for i,x in enumerate(dat)])\n",
    "    if 'trough' in c:\n",
    "        DataObserved2015['temperature-trough-%scm'%k] = d\n",
    "    elif 'center' in c and not 'off' in c :\n",
    "        DataObserved2015['temperature-center-%scm'%k] = d\n",
    "    elif 'rim' in c and 'rim2' not in c:\n",
    "        if k > 2:\n",
    "            k = k + 1*0\n",
    "        DataObserved2015['temperature-rim-%scm'%k] = d\n",
    "        \n",
    "    if 'Time' in c:\n",
    "        time1 = [pd.to_datetime(data4['Timestamp'])]\n",
    "        time = [(t - time_origin).dt.total_seconds()/86400 for t in time1]\n",
    "        Time = np.array([start_year +t/365. for t in time[0]])\n",
    "        #Time = np.array([t for t in time[0]])\n",
    "        DataObserved2015['time'] = np.array(Time)\n",
    "        DataObserved2015['time_yr'] = [2010 + t/365 for t in Time]\n",
    "\"\"\"     \n",
    "for c in data5.columns:\n",
    "    k = -100\n",
    "    if 'trough' in c or 'center' in c or 'rim' in c:\n",
    "        k = int(float(c[6:10])*100)\n",
    "        dat = np.array([ x + 273.15  for x in data5[c]])\n",
    "        d = np.array([dat[i-1] if np.isnan(x) else x for i,x in enumerate(dat)])\n",
    "    if 'trough' in c:\n",
    "        DataObserved2016['temperature-trough-%scm'%k] = d\n",
    "    elif 'center' in c and not 'off' in c :\n",
    "        DataObserved2016['temperature-center-%scm'%k] = d\n",
    "    elif 'rim' in c and 'rim2' not in c:\n",
    "        if k > 2:\n",
    "            k = k + 1*0\n",
    "        DataObserved2016['temperature-rim-%scm'%k] = d\n",
    "        \n",
    "        \n",
    "    if 'Time' in c:\n",
    "        time1 = [pd.to_datetime(data5['Timestamp'])]\n",
    "        time = [(t - time_origin).dt.total_seconds()/86400 for t in time1]\n",
    "        Time = np.array([start_year +t/365. for t in time[0]])\n",
    "        #Time = np.array([t for t in time[0]])\n",
    "        DataObserved2016['time'] = np.array(Time)\n",
    "        DataObserved2016['time_yr'] = [2010 + t/365 for t in Time]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Snow\n",
    "def ObservedSnow(location='Center'):\n",
    "    SnowData = dict()\n",
    "    infile = '/Users/ajc/Desktop/SimDataInputs/barrow-polygon-data/Vladimir-Data/SnowDepth/'\n",
    "    infile_observed1 = infile + 'C_Snow_%s_2012-2013.csv'%location\n",
    "    infile_observed2 = infile + 'C_Snow_%s_2013-2014.csv'%location\n",
    "    datasnow1 = pd.read_csv(infile_observed1,skiprows=3)\n",
    "    datasnow2 = pd.read_csv(infile_observed2,skiprows=3)\n",
    "\n",
    "    dat1 = np.array([ x for x in datasnow1['1 Hour Moving Average']])\n",
    "    dat2 = np.array([ x for x in datasnow2['1 Hour Moving Average']])\n",
    "    \n",
    "    #SnowData1 = np.array([x/100. if x < 50 else .5 for i,x in enumerate(dat1)])\n",
    "    #SnowData2 = np.array([x/100. if x < 50 else .5 for i,x in enumerate(dat2)])\n",
    "    \n",
    "    SnowData1 = np.array([x/1. for i,x in enumerate(dat1)])\n",
    "    SnowData2 = np.array([x/1. for i,x in enumerate(dat2)])\n",
    "    \n",
    "    time1 = [pd.to_datetime(datasnow1['TZ=UTC+0'])]\n",
    "    time = np.array([(t - time_origin).dt.total_seconds()/86400 for t in time1])\n",
    "    TimeSnow1 = np.array([t/365.25 for t in time[0]])\n",
    "    \n",
    "    \n",
    "    time1 = [pd.to_datetime(datasnow2['TZ=UTC+0'])]\n",
    "    time = np.array([(t - time_origin).dt.total_seconds()/86400 for t in time1])\n",
    "    TimeSnow2 = np.array([t/365.25 for t in time[0]])\n",
    "    \n",
    "   \n",
    "    mask = np.ones(len(SnowData1), dtype=bool)\n",
    "    for i,d in enumerate(SnowData1):\n",
    "        if d > 6000 or d < 0:\n",
    "            mask[i] = False\n",
    "    SnowData1 = SnowData1[mask]\n",
    "    TimeSnow1 = TimeSnow1[mask]\n",
    "    SnowData1 = SnowData1 / 100.\n",
    "    L1 = len(SnowData1) - len(SnowData1)%24\n",
    "    \n",
    "    SnowData1 = np.reshape(SnowData1[:L1], (-1,24)).mean(axis=1)\n",
    "    TimeSnow1 = np.reshape(TimeSnow1[:L1], (-1,24)).mean(axis=1)\n",
    "    \n",
    "    mask = np.ones(len(SnowData2), dtype=bool)\n",
    "    for i,d in enumerate(SnowData2):\n",
    "        if d > 6000 or d < 0:\n",
    "            mask[i] = False\n",
    "    SnowData2 = SnowData2[mask]\n",
    "    TimeSnow2 = TimeSnow2[mask]\n",
    "\n",
    "    SnowData2 = SnowData2 / 100.\n",
    "    \n",
    "    L2 = len(SnowData2) - len(SnowData2)%24\n",
    "    \n",
    "    SnowData2 = np.reshape(SnowData2[:L2], (-1,24)).mean(axis=1)\n",
    "    TimeSnow2 = np.reshape(TimeSnow2[:L2], (-1,24)).mean(axis=1)\n",
    "    SnowData['snow_time_%s'%location] = np.concatenate((TimeSnow1, TimeSnow2))\n",
    "    SnowData['snow_depth_%s'%location] = np.concatenate((SnowData1,SnowData2))\n",
    "\n",
    "    return SnowData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataObservedSnow = dict()\n",
    "\n",
    "DataObservedSnow = ObservedSnow('Center')\n",
    "d2 = ObservedSnow('Rim')\n",
    "d3 = ObservedSnow('Trough')\n",
    "DataObservedSnow.update(d2)\n",
    "DataObservedSnow.update(d3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def sorted_nicely( l ):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key = alphanum_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulation = ['SiteC_3D_3R1A', 'SiteC_3D_3R2A'] # Sensitivity tests 1A (undercatch adjustest, 2A no undercatch adjustmetn)\n",
    "simulation = ['SiteC_3D_3R1C', 'SiteC_3D_3R1F'] # Sensitivty tests 1B no limiter on snow density, 1C limiter on snow density (basecase)\n",
    "path = \"/Users/ajc/Projects/ATS-Data/OR-CONDO/simulations/barrow_icewedges/NGEE/SiteC_3D_June10/\"\n",
    "\n",
    "dir_files = os.listdir(path + simulation[0])\n",
    "Vars = ['temperature-center', 'temperature-right-trough', 'temperature-rim']\n",
    "SimName = ['S1', 'S2']\n",
    "Files = dict()\n",
    "for var in Vars:\n",
    "    Files_Temp = [f for f in dir_files if f.startswith(var)]\n",
    "    Files[var] = sorted_nicely(Files_Temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DataSimAll= dict()\n",
    "\n",
    "temp_C = []\n",
    "for i,sim in enumerate(simulation):\n",
    "    Sname = SimName[i] + '-'\n",
    "    for var in Vars:\n",
    "        for files in Files[var]:\n",
    "            dat = rd.ReadSingleFile(os.path.join(path+sim,files))\n",
    "            DataSimAll[Sname + files[:-4]] = np.array(dat['data'])\n",
    "            time = [t/86400. for t in dat['time']]\n",
    "            #print (files,len(dat['time']), len(dat['data']))\n",
    "            assert len(dat['data']) == len(dat['time'])\n",
    "\n",
    "DataSim1 = dict()\n",
    "DataSim2 = dict()\n",
    "DataSim1['Time'] = [2010 + t/365. for t in time]\n",
    "\n",
    "print (len(DataSim1['Time']))\n",
    "for key in list(DataSimAll):#.keys():\n",
    "    if SimName[0] in key:\n",
    "        DataSim1[key[3:]] = DataSimAll[key]\n",
    "    if SimName[1] in key:\n",
    "        DataSim2[key[3:]] = DataSimAll[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in list(DataSim1):#.keys():\n",
    "    if 'temperature-right-trough' in key:\n",
    "        K = key.replace('right-',\"\")\n",
    "        DataSim1[K] = DataSim1[key]\n",
    "        DataSim2[K] = DataSim2[key]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def put_axis(dep, loc=''):\n",
    "    #plt.text(2013.5, 246, 'Depth = %s'%(dep),fontsize=11, fontweight='normal')\n",
    "    plt.ylim((245, 285))\n",
    "    plt.yticks(np.linspace(245,285, 5))\n",
    "    #plt.xlim((2012.7, 2015))    \n",
    "    plt.xlim((2013.8, 2015))\n",
    "    plt.text(2013.85, 246, 'Depth = %s'%(dep),fontsize=11, fontweight='normal')\n",
    "DataObserved2012Daily = dict()\n",
    "DataObserved2013Daily = dict()\n",
    "DataObserved2014Daily = dict()\n",
    "DataObserved2015Daily = dict()\n",
    "DataObserved2016Daily = dict()\n",
    "L2012 = len(DataObserved2012['temperature-trough-2cm'])\n",
    "R2012 = L2012%24\n",
    "\n",
    "for key in list(DataObserved2012):#.iteritems():\n",
    "    DataObserved2012Daily[key] = np.reshape(DataObserved2012[key][:-R2012], (-1, 24)).mean(axis=1)\n",
    "\n",
    "L2013 = len(DataObserved2013['temperature-trough-2cm'])\n",
    "R2013 = L2013%24\n",
    "\n",
    "for key in list(DataObserved2013):#.iteritems():\n",
    "    DataObserved2013Daily[key] = np.reshape(DataObserved2013[key][:-R2013], (-1, 24)).mean(axis=1)\n",
    "\n",
    "L2014 = len(DataObserved2014['temperature-trough-2cm'])\n",
    "R2014 = L2014%24\n",
    "\n",
    "for key in list(DataObserved2014):#.iteritems():\n",
    "    DataObserved2014Daily[key] = np.reshape(DataObserved2014[key][:-R2014], (-1, 24)).mean(axis=1)\n",
    "\n",
    "L2015 = len(DataObserved2015['temperature-trough-2cm'])\n",
    "R2015 = L2015%24\n",
    "\n",
    "for key in sorted(list(DataObserved2015)):#.iteritems()):\n",
    "    DataObserved2015Daily[key] = np.reshape(DataObserved2015[key][:-R2015], (-1, 24)).mean(axis=1)\n",
    "\n",
    "#L2016 = len(DataObserved2016['temperature-trough-2cm'])\n",
    "#R2016 = L2016%24\n",
    "\n",
    "#for key in sorted(list(DataObserved2016)):#.iteritems()):\n",
    "#    DataObserved2016Daily[key] = np.reshape(DataObserved2016[key][:-R2016], (-1, 24)).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataObserved2012Daily['time_yr'] = [DataObserved2012Daily['time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataSimulationUpdate(DataSim):\n",
    "    DataSimUpdate = dict()\n",
    "    KeysRim = [2,6,11,21,31,46,66,96,146]\n",
    "    for key in list(DataObserved2013Daily):#.keys():\n",
    "        if key in DataSim.keys() and 'rim' in key:\n",
    "            DataSimUpdate[key] = DataSim[key]\n",
    "        elif 'rim' in key:\n",
    "            index = int(key[key.rfind('-')+1:-2])\n",
    "            if index in KeysRim:\n",
    "                var1 = key[:key.rfind('-')+1] + str(index-1) + 'cm'\n",
    "                var2 = key[:key.rfind('-')+1] + str(index+1) + 'cm'\n",
    "                dat = [0.5*(d1+d2) for d1,d2 in zip(DataSim[var1], DataSim[var2])]\n",
    "                DataSimUpdate[key] = np.array(dat)\n",
    "    KeysTrough = [5,10,15,25,35,50,70,100,150]\n",
    "    for key in list(DataObserved2013Daily):#.keys():\n",
    "        if key in DataSim.keys() and ('center' in key or 'trough' in key):\n",
    "            DataSimUpdate[key] = DataSim[key]\n",
    "        elif 'trough' in key or 'center' in key:\n",
    "            index = int(key[key.rfind('-')+1:-2])\n",
    "            if index in KeysTrough:\n",
    "                var1 = key[:key.rfind('-')+1] + str(index-1) + 'cm'\n",
    "                var2 = key[:key.rfind('-')+1] + str(index+1) + 'cm'\n",
    "                dat = [0.5*(d1+d2) for d1,d2 in zip(DataSim[var1], DataSim[var2])]\n",
    "                DataSimUpdate[key] = np.array(dat)\n",
    "    return DataSimUpdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = '/Users/ajc/AllPostProcessData/2019/simulations/barrow-iwp/July16/Temp3D/'\n",
    "#outfileSnow = '/Users/ajc/AllPostProcessData/2019/simulations/barrow-iwp/May15/Snow3D/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSim1Update = DataSimulationUpdate(DataSim1)\n",
    "DataSim2Update = DataSimulationUpdate(DataSim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "def plot_at_depths(location = 'trough', sending='sending'):\n",
    "    print (\"PLOTTING\",sending)\n",
    "    fig, axs = plt.subplots(3,1, figsize=(5,6), facecolor='w', edgecolor='k',gridspec_kw={'width_ratios':[1]})\n",
    "    fig.subplots_adjust(hspace =.02, wspace=1.02)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    axs = axs.ravel()\n",
    "    Keys = list(DataObserved2013Daily)#.keys()\n",
    "    Keys_st = []\n",
    "    \n",
    "    Vars = ['temperature-trough-5cm','temperature-trough-50cm','temperature-trough-150cm']\n",
    "    for i in range(0,3):\n",
    "        x='31'+str(i+1)\n",
    "        ax = plt.subplot(x)\n",
    "        var = Vars[i]\n",
    "        print (var)\n",
    "        plt.plot(DataObserved2012Daily['time'],  DataObserved2012Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2013Daily['time'],  DataObserved2013Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2014Daily['time'],  DataObserved2014Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2015Daily['time'],  DataObserved2015Daily[var],'r',linestyle='-',label='Observed')\n",
    "        \n",
    "        plt.plot(DataSim1['Time'][::1], DataSim1Update[var][::1],'k-',linestyle='--',label='Undercatch adjustmemt')\n",
    "        plt.plot(DataSim1['Time'][::1], DataSim2Update[var][::1],'b-',linestyle='--',label='No undercatch adjustmetnt')\n",
    "        \n",
    "        if i == 0:\n",
    "            plt.title('Trough',fontsize=12, fontweight='bold')\n",
    "        plt.axhline(y=273.15,linestyle='--',color='g')\n",
    "        plt.ylabel('Soil temperature [K]')\n",
    "        \n",
    "        \n",
    "        put_axis(var[var.rfind('-')+1:-2] + ' cm', loc='Trough')\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.legend(loc='upper right', fontsize=8, ncol=3, bbox_to_anchor=(0.55,-0.32, .4, .0))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outfile+'%s-temp-%s.pdf'%(simulation[0] + simulation[1], location), bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLOTTING YES\n",
      "temperature-trough-5cm\n",
      "temperature-trough-50cm\n",
      "temperature-trough-150cm\n"
     ]
    }
   ],
   "source": [
    "plot_at_depths(sending='YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "def plot_at_depths_AgingModel(location = 'trough'):\n",
    "    \n",
    "    fig, axs = plt.subplots(3,1, figsize=(5.5,6), facecolor='w', edgecolor='k',gridspec_kw={'width_ratios':[1]})\n",
    "    fig.subplots_adjust(hspace =.02, wspace=1.02)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    axs = axs.ravel()\n",
    "    Keys = list(DataObserved2013Daily)#.keys()\n",
    "    Keys_st = []\n",
    "    \n",
    "    Vars = ['temperature-trough-5cm','temperature-trough-50cm','temperature-trough-150cm']\n",
    "    for i in range(0,3):\n",
    "        x='31'+str(i+1)\n",
    "        ax = plt.subplot(x)\n",
    "        var = Vars[i]\n",
    "        print (var)\n",
    "        plt.plot(DataObserved2012Daily['time'],  DataObserved2012Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2013Daily['time'],  DataObserved2013Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2014Daily['time'],  DataObserved2014Daily[var],'r',linestyle='-')\n",
    "        plt.plot(DataObserved2015Daily['time'],  DataObserved2015Daily[var],'r',linestyle='-',label='Observed')\n",
    "        \n",
    "        plt.plot(DataSim1['Time'][::1], DataSim1Update[var][::1],'k-',linestyle='--',label='With snow aging model')\n",
    "        plt.plot(DataSim1['Time'][::1], DataSim2Update[var][::1],'b-',linestyle='--',label='Without snow aging model')\n",
    "        \n",
    "        if i == 0:\n",
    "            plt.title('Trough',fontsize=12, fontweight='bold')\n",
    "        plt.axhline(y=273.15,linestyle='--',color='g')\n",
    "        plt.ylabel('Soil temperature [K]')\n",
    "        \n",
    "        \n",
    "        put_axis(var[var.rfind('-')+1:-2] + ' cm', loc='Trough')\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.legend(loc='upper right', fontsize=8, ncol=3, bbox_to_anchor=(0.65,-0.32, .4, .0))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outfile+'%s-temp-%s.pdf'%(simulation[0] + simulation[1], location), bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature-trough-5cm\n",
      "temperature-trough-50cm\n",
      "temperature-trough-150cm\n"
     ]
    }
   ],
   "source": [
    "plot_at_depths_AgingModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellid = 0\n",
    "\n",
    "surfdata = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-precipitation_rain', cellid=cellid)\n",
    "plt.plot(surfdata['surface-precipitation_rain'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vars = ['precipitation_rain', 'thermal_conductivity', 'ponded_depth']\n",
    "vars = ['surface-' + v for v in vars]\n",
    "fig, axs = plt.subplots(3,3, figsize=(8,8), facecolor='w', edgecolor='k',gridspec_kw={'width_ratios':[1,1,1]})\n",
    "fig.subplots_adjust(hspace =.02, wspace=1.02)\n",
    "plt.tight_layout()\n",
    "axs = axs.ravel()\n",
    "for i in range(1,4):\n",
    "    x='33'+str(i)\n",
    "    plt.subplot(x)\n",
    "    snow_depth = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', vars[i-1], cellid=cellid)\n",
    "    plt.plot(DataSim['time_d'],snow_depth[vars[i-1]],'-')\n",
    "    plt.ylabel('%s'%vars[i-1])\n",
    "    plt.xlim(4,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['snow-age', 'snow-depth', 'snow-conductivity','snow-density','snow-precipitation', 'snow-swe', 'surface-air_temperature', 'surface-temperature', 'snow-temperature']\n",
    "\n",
    "fig, axs = plt.subplots(3,3, figsize=(8,8), facecolor='w', edgecolor='k',gridspec_kw={'width_ratios':[1,1,1]})\n",
    "fig.subplots_adjust(hspace =.02, wspace=1.02)\n",
    "plt.tight_layout()\n",
    "axs = axs.ravel()\n",
    "SimTime  = np.array([t/365.25 for t in DataSim['time_d']])\n",
    "SnowData = dict()\n",
    "snow_annual = 0\n",
    "snow_time = 0\n",
    "snow_fall = []\n",
    "for i in range(1,10):\n",
    "    x='33'+str(i)\n",
    "    plt.subplot(x)\n",
    "    if 'snow' in vars[i-1]:\n",
    "        snow_depth = rd.GetSurfVarFromVis(infile_simulated+'/visdump_snow_data.h5', vars[i-1], cellid=cellid)\n",
    "    else:\n",
    "        snow_depth = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', vars[i-1], cellid=cellid)\n",
    "            \n",
    "    SnowData.update(snow_depth)\n",
    "    if 'precip' in vars[i-1]:\n",
    "        snow_annual = np.reshape(SnowData['snow-precipitation'][:5*365],(365,5)).sum(axis=0)\n",
    "        snow_time = np.reshape(SimTime[:5*365],(5,365)).mean(axis=1)\n",
    "        sum1, sum2, sum3 = 0,0,0\n",
    "        for j,sn in enumerate(SimTime):\n",
    "            if sn >2.5 and sn <3.5:\n",
    "                sum1 = sum1 + SnowData['snow-precipitation'][j]\n",
    "            if sn >3.5 and sn <4.5:\n",
    "                sum2 = sum2 + SnowData['snow-precipitation'][j]\n",
    "            if sn >4.5 and sn <5.5:\n",
    "                sum3 = sum3 + SnowData['snow-precipitation'][j]\n",
    "                \n",
    "        snow_fall = [sum1, sum2, sum3]\n",
    "        snow_time = [3.0,4.0, 5.0]\n",
    "        print snow_fall, snow_time\n",
    "        plt.ylim(0,2.5e-7)\n",
    "        plt.plot(SimTime,snow_depth[vars[i-1]],'-')\n",
    "        plt.ylabel('%s'%vars[i-1])\n",
    "        ax0  = plt.twinx()\n",
    "        ax0.plot(snow_time,snow_fall,'*', color='g')\n",
    "        ax0.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "        ax0.set_ylim(0,1.0e-5)\n",
    "        ax0.set_ylabel('Mean snow precip')\n",
    "        \n",
    "        \n",
    "    if not 'precip' in vars[i-1]:\n",
    "        plt.plot(SimTime,snow_depth[vars[i-1]],'-', color='k')\n",
    "        plt.ylabel('%s'%vars[i-1])\n",
    "    if 'temperature' in vars[i-1]:\n",
    "        plt.axhline(y=273.15,color ='c',linestyle='--')\n",
    "    if 'snow-depth' in vars[i-1]:\n",
    "        plt.plot(DataObservedSnow['snow_time_Center'], DataObservedSnow['snow_depth_Center'],'.',color='r',markersize=2,label='Center')\n",
    "        #plt.plot(DataObservedSnow['snow_time_Rim'], DataObservedSnow['snow_depth_Rim'],'.',color='g',markersize=2,label='Rim')\n",
    "        #plt.plot(DataObservedSnow['snow_time_Trough'], DataObservedSnow['snow_depth_Trough'],color='b',markersize=2,label='Trough')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.xlim(2.5,5.5)\n",
    "    \n",
    "\n",
    "      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_depth_T = rd.GetSurfVarFromVis(infile_simulated+'/visdump_snow_data.h5', 'snow-depth', cellid=0)\n",
    "snow_depth_R = rd.GetSurfVarFromVis(infile_simulated+'/visdump_snow_data.h5', 'snow-depth', cellid=10)\n",
    "snow_depth_C = rd.GetSurfVarFromVis(infile_simulated+'/visdump_snow_data.h5', 'snow-depth', cellid=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_T = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-elevation', cellid=0)\n",
    "Z_R = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-elevation', cellid=10)\n",
    "Z_C = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-elevation', cellid=37)\n",
    "print Z_T['surface-elevation'][0], Z_R['surface-elevation'][0], Z_C['surface-elevation'][0]\n",
    "\n",
    "surf_pd_T = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-ponded_depth', cellid=0)\n",
    "surf_pd_R = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-ponded_depth', cellid=10)\n",
    "surf_pd_C = rd.GetSurfVarFromVis(infile_simulated+'/visdump_surface_data.h5', 'surface-ponded_depth', cellid=37)\n",
    "print surf_pd_T['surface-ponded_depth'][0], surf_pd_R['surface-ponded_depth'][0], surf_pd_C['surface-ponded_depth'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['snow-depth']\n",
    "\n",
    "fig, axs = plt.subplots(3,1, figsize=(9,4), facecolor='w', edgecolor='k',gridspec_kw={'width_ratios':[1]})\n",
    "fig.subplots_adjust(hspace =.02, wspace=0.25)\n",
    "plt.tight_layout()\n",
    "axs = axs.ravel()\n",
    "SimTime  = np.array([t/365.25 for t in DataSim['time_d']])\n",
    "SnowData = dict()\n",
    "\n",
    "Elev = 1\n",
    "pd = 1\n",
    "plt.subplot(131)\n",
    "snow_depth_Tr = [ pd*d1 + Z_T['surface-elevation'][0]*Elev + d2 for d1,d2 in zip(surf_pd_T['surface-ponded_depth'],snow_depth_T['snow-depth']) ]\n",
    "DataObservedSnowT = [Z_T['surface-elevation'][0]*Elev + d for d in DataObservedSnow['snow_depth_Trough'] ]\n",
    "plt.plot(SimTime, snow_depth_Tr,marker='*',color='k',label='Sim Trough')\n",
    "plt.plot(DataObservedSnow['snow_time_Trough'], DataObservedSnowT,'.',color='r',label='Observed Trough')\n",
    "plt.legend(loc='upper left',fontsize=6)\n",
    "plt.xlim(2.5,5.5)\n",
    "if Elev > 0:\n",
    "    plt.ylim(4.9,5.8)\n",
    "else:\n",
    "    plt.ylim(0,0.7)\n",
    "plt.ylabel('Snow depth [m]')\n",
    "plt.xlabel('Time [yr]')\n",
    "\n",
    "plt.subplot(132)\n",
    "snow_depth_Ri = [ pd*d1 + Z_R['surface-elevation'][0]*Elev + d2 for d1,d2 in zip(surf_pd_R['surface-ponded_depth'],snow_depth_R['snow-depth']) ]\n",
    "DataObservedSnowR = [Z_R['surface-elevation'][0]*Elev + d for d in DataObservedSnow['snow_depth_Rim'] ]\n",
    "plt.plot(SimTime, snow_depth_Ri,color='k',marker='*',label='Sim Rim')\n",
    "plt.plot(DataObservedSnow['snow_time_Rim'], DataObservedSnowR,'.',color='r',label='Observed Rim')\n",
    "plt.legend(loc='upper left',fontsize=6)\n",
    "plt.xlim(2.5,5.5)\n",
    "if Elev > 0:\n",
    "    plt.ylim(4.9,5.8)\n",
    "else:\n",
    "    plt.ylim(0,0.7)\n",
    "\n",
    "plt.ylabel('Snow depth [m]')\n",
    "plt.xlabel('Time [yr]')\n",
    "\n",
    "plt.subplot(133)\n",
    "snow_depth_Ce = [ pd*d1 + Z_C['surface-elevation'][0]*Elev + d2 for d1,d2 in zip(surf_pd_C['surface-ponded_depth'],snow_depth_C['snow-depth']) ]\n",
    "DataObservedSnowC = [Z_C['surface-elevation'][0]*Elev + d for d in DataObservedSnow['snow_depth_Center'] ]\n",
    "plt.plot(SimTime, snow_depth_Ce,color='k',marker='*',label='Sim Center')\n",
    "plt.plot(DataObservedSnow['snow_time_Center'], DataObservedSnowC,'.',color='r',label='Observed Center')\n",
    "plt.ylabel('Snow depth [m]')\n",
    "plt.xlabel('Time [yr]')\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left',fontsize=6)\n",
    "\n",
    "plt.xlim(2.5,5.5)\n",
    "if Elev > 0:\n",
    "    plt.ylim(4.9,5.8)\n",
    "else:\n",
    "    plt.ylim(0,0.7)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(outfileSnow+'%s-snow.pdf'%(simulation), bbox_inches='tight', dpi=100)\n",
    "      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['snow-depth']\n",
    "\n",
    "fig, axs = plt.subplots(3,1, figsize=(9,4), facecolor='w', edgecolor='k',gridspec_kw={'width_ratios':[1]})\n",
    "fig.subplots_adjust(hspace =.02, wspace=0.25)\n",
    "plt.tight_layout()\n",
    "axs = axs.ravel()\n",
    "#SimTime  = np.array([t/365.25 for t in DataSim['time_d']])\n",
    "SnowData = dict()\n",
    "\n",
    "Elev = 0\n",
    "plt.subplot(131)\n",
    "snow_depth_Tr = [ Z_T['surface-elevation'][0]*Elev + d for d in snow_depth_T['snow-depth'] ]\n",
    "DataObservedSnowT = [Z_T['surface-elevation'][0]*Elev + d for d in DataObservedSnow['snow_depth_Trough'] ]\n",
    "plt.plot(snow_depth_Tr,marker='*',color='k',label='Sim Trough')\n",
    "#plt.plot(DataObservedSnow['snow_time_Trough'], DataObservedSnowT,'.',color='r',label='Observed Trough')\n",
    "plt.legend(loc='upper left',fontsize=6)\n",
    "#plt.xlim(2.5,5.5)\n",
    "if Elev > 0:\n",
    "    plt.ylim(4.9,5.8)\n",
    "else:\n",
    "    plt.ylim(0,0.7)\n",
    "plt.ylabel('Snow depth [m]')\n",
    "plt.xlabel('Time [yr]')\n",
    "\n",
    "plt.subplot(132)\n",
    "snow_depth_Ri = [ Z_R['surface-elevation'][0]*Elev + d for d in snow_depth_R['snow-depth'] ]\n",
    "DataObservedSnowR = [Z_R['surface-elevation'][0]*Elev + d for d in DataObservedSnow['snow_depth_Rim'] ]\n",
    "plt.plot(snow_depth_Ri,color='k',marker='*',label='Sim Rim')\n",
    "#plt.plot(DataObservedSnow['snow_time_Rim'], DataObservedSnowR,'.',color='r',label='Observed Rim')\n",
    "plt.legend(loc='upper left',fontsize=6)\n",
    "#plt.xlim(2.5,5.5)\n",
    "if Elev > 0:\n",
    "    plt.ylim(4.9,5.8)\n",
    "else:\n",
    "    plt.ylim(0,0.7)\n",
    "\n",
    "plt.ylabel('Snow depth [m]')\n",
    "plt.xlabel('Time [yr]')\n",
    "\n",
    "plt.subplot(133)\n",
    "snow_depth_Ce = [ Z_C['surface-elevation'][0]*Elev + d for d in snow_depth_C['snow-depth'] ]\n",
    "DataObservedSnowC = [Z_C['surface-elevation'][0]*Elev + d for d in DataObservedSnow['snow_depth_Center'] ]\n",
    "plt.plot(snow_depth_Ce,color='k',marker='*',label='Sim Center')\n",
    "#plt.plot(DataObservedSnow['snow_time_Center'], DataObservedSnowC,'.',color='r',label='Observed Center')\n",
    "plt.ylabel('Snow depth [m]')\n",
    "plt.xlabel('Time [yr]')\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left',fontsize=6)\n",
    "\n",
    "#plt.xlim(2.5,5.5)\n",
    "if Elev > 0:\n",
    "    plt.ylim(4.9,5.8)\n",
    "else:\n",
    "    plt.ylim(0,0.7)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(outfileSnow+'%s-snow.pdf'%(simulation), bbox_inches='tight', dpi=100)\n",
    "      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_vol = rd.GetSurfVarFromVis(infile_simulated+'/visdump_snow_data.h5', 'snow-cell_volume', cellid=cellid)\n",
    "swe_comp = np.zeros(len(SnowData['snow-depth']))\n",
    "swe_sim = np.zeros(len(SnowData['snow-depth']))\n",
    "for i in range(len(swe_comp)):\n",
    "    swe_comp[i] = (SnowData['snow-depth'][i] * SnowData['snow-density'][i]) / 1000.\n",
    "    swe_sim[i] = SnowData['snow-swe'][i] / cell_vol['snow-cell_volume'][i]\n",
    "    \n",
    "#plt.plot(SimTime,SnowData['snow-swe'],'r',label='simulated')\n",
    "plt.plot(SimTime,swe_sim,'g',label='simulated')\n",
    "plt.plot(SimTime, swe_comp,'k.',label='computed SWE = (snow_depth *snow_density) / 1000.')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('SWE [m]')\n",
    "plt.legend()\n",
    "plt.xlim(2.5,5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snow conductivity\n",
    "Snow_thermal_cond = []\n",
    "Snow_heat_cond = []\n",
    "for d in SnowData['snow-density']:\n",
    "    Snow_thermal_cond.append(2.9 * 10e-6 * d ** 2 )\n",
    "\n",
    "for i in range(len(SnowData['snow-density'])):\n",
    "    if SnowData['snow-depth'][i] > 0.0:\n",
    "        if SnowData['surface-temperature'][i] <= SnowData['snow-temperature'][i]:\n",
    "            K = -(SnowData['surface-temperature'][i] - SnowData['snow-temperature'][i]) / SnowData['snow-depth'][i]\n",
    "    else:\n",
    "        K = 0\n",
    "    Snow_heat_cond.append(Snow_thermal_cond[i] * K)\n",
    "    \n",
    "#plt.plot(SimTime, Snow_thermal_cond)\n",
    "plt.plot(SimTime, Snow_heat_cond,'.')\n",
    "plt.ylabel('Effective thermal cond snow [W/m K]')\n",
    "plt.xlabel('Time [yr]')\n",
    "plt.xlim(3.5,5.5)\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "snow_yr = np.reshape(SnowData['snow-precipitation'][:5*365],(365,5)).sum(axis=0)\n",
    "print snow_yr\n",
    "snow_time = np.reshape(SimTime[:5*365],(365,5)).mean(axis=0)\n",
    "print snow_time\n",
    "print SimTime.shape()\n",
    "print np.reshape(SimTime[:2*365],(2,365)).mean(axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnnaData = h5py.File('/Users/ajc/Desktop/ATS/forcing_data/Barrow-Anna-WaterLevel/Barrow-2010_2016-updated.h5')\n",
    "AdamsData = h5py.File('/Users/ajc/Desktop/ATS/forcing_data/Adams_data/NewBarrow_2013.h5')\n",
    "AdamsTime = [2013 + t/(86400*365) for t in AdamsData['time (met) [s]']]\n",
    "AnnaTime = [2010 + t/(86400*365) for t in AnnaData['time [s]']]\n",
    "\n",
    "plt.plot(AdamsTime[:365],AdamsData['precipitation snow [m s^-1]'][:365],'r', label='Adams: Snow precip')\n",
    "plt.plot(AdamsTime[:365],AdamsData['precipitation snow [m s^-1]'][365:],'g.', label='Adams: Snow precip')\n",
    "plt.plot(AnnaTime,AnnaData['precipitation snow [m SWE s^-1]'],'k', label='Anna: Snow precip')\n",
    "plt.ylabel('Snow precipitation')\n",
    "plt.xlim(2013,2015)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
