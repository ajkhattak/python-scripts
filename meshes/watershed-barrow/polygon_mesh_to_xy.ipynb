{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapefile\n",
    "import numpy as np\n",
    "import sys,os\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import collections\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['ATS_SRC_DIR'],'tools','meshing_ats','meshing_ats'))\n",
    "\n",
    "import meshing_ats\n",
    "eps = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(p0,p1):\n",
    "    return np.linalg.norm(p0.x - p1.x)\n",
    "\n",
    "def is_equal(p0,p1,eps=1.0):\n",
    "    if (dist(p0,p1) < eps):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def centroid(points):\n",
    "    return Point(sum(p.x for p in points)/len(points))\n",
    "\n",
    "def ccw(A, B, C):\n",
    "    \"\"\"Tests whether the turn formed by A, B, and C is ccw\"\"\"\n",
    "    return (B.x[0] - A.x[0]) * (C.x[1] - A.x[1]) > (B.x[1] - A.x[1]) * (C.x[0] - A.x[0])\n",
    "\n",
    "def convex(points):\n",
    "    \"\"\"Returns 1 if convex, ccw ordered, -1 if convex but cw ordered, 0 if not convex\"\"\"\n",
    "    is_ccw = []\n",
    "    for i in range(len(points)):\n",
    "        # Check every triplet of points\n",
    "        A = points[i % len(points)]\n",
    "        B = points[(i + 1) % len(points)]\n",
    "        C = points[(i + 2) % len(points)]\n",
    "        is_ccw.append(ccw(A,B,C))\n",
    "    if all(is_ccw):\n",
    "        return 1\n",
    "    elif all([not(c) for c in is_ccw]):\n",
    "        return -1\n",
    "    return 0    \n",
    "\n",
    "def star_convex(points):\n",
    "    \"\"\"Returns 1 if star-convex, ccw ordered, -1 if star-convex but cw ordered, 0 if not star-convex\"\"\"\n",
    "    cent = centroid(points)\n",
    "    convex_tris = []\n",
    "    for i in range(len(points)):\n",
    "        tri_points = [points[i], points[(i+1)%len(points)], cent]\n",
    "        convex_tris.append(convex(tri_points))\n",
    "    if all([cv_tri == 1 for cv_tri in convex_tris]):\n",
    "        return 1\n",
    "    elif all([cv_tri == -1 for cv_tri in convex_tris]):\n",
    "        return -1\n",
    "    return 0    \n",
    "\n",
    "class Point(object):\n",
    "    def __init__(self, x, decimals=1):\n",
    "        self.x = np.array(x)\n",
    "        self.xr = np.array([np.round(self.x[0],decimals), \n",
    "                            np.round(self.x[1],decimals)])\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash(tuple(self.xr))\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return is_equal(self, other, eps)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Point: (%12.10g,%12.10g)\"%(self.xr[0],self.xr[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959\n"
     ]
    }
   ],
   "source": [
    "# read the polygons via shapefile\n",
    "sf_poly = shapefile.Reader(\"./Polygon_mesh_final/Polygon_mesh_final\")\n",
    "polygons = sf_poly.shapes()\n",
    "\n",
    "nodes = []\n",
    "conn = []\n",
    "\n",
    "for s in polygons:\n",
    "    poly_conn = []\n",
    "    for p in s.points:\n",
    "        myp = Point(p)\n",
    "        if len(nodes) > 0:\n",
    "            i = np.argmin(np.array([dist(myp, lcv) for lcv in nodes]))\n",
    "\n",
    "            min_dist = dist(myp, nodes[i])\n",
    "            if min_dist > eps:\n",
    "                poly_conn.append(len(nodes))\n",
    "                nodes.append(myp)\n",
    "            else:\n",
    "                poly_conn.append(i)\n",
    "        else:\n",
    "            nodes.append(myp)\n",
    "            poly_conn.append(0)\n",
    "    conn.append(poly_conn)\n",
    "    \n",
    "print (len(nodes))\n",
    "\n",
    "xyz_nodes = np.zeros((len(nodes),3),'d')\n",
    "for i,n in enumerate(nodes):\n",
    "    xyz_nodes[i,0:2] = n.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the nodes file\n",
    "with open(\"./Polygon_mesh_nodes_final.csv\",'w') as fid:\n",
    "    fid.write(\"point ID,X,Y\\n\")\n",
    "    for i,n in enumerate(nodes):\n",
    "        fid.write(\"%d,%16.16g,%16.16g\\n\"%(i,n.x[0],n.x[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the resulting shapefile with x,y,z nodes\n",
    "sf_points = shapefile.Reader(\"./Polygon_mesh_nodes_sample_final/Polygon_mesh_nodes_sample_final\")\n",
    "shapes = sf_points.shapes()\n",
    "\n",
    "xyz_points = np.array([[p.points[0][0], p.points[0][1], p.z[0]] for p in shapes])\n",
    "points = [Point(xyz_points[i,0:2]) for i in range(xyz_points.shape[0])]\n",
    "\n",
    "# match nodes to xyz_points\n",
    "for i,n in enumerate(nodes):\n",
    "    j_closest = np.argmin(np.array([dist(n,p) for p in points]))\n",
    "    xyz_nodes[i,2] = xyz_points[j_closest,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potentially strip duplicate points\n",
    "for c in conn:\n",
    "    if c[0] == c[-1]:\n",
    "        c.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib \n",
    "# make the 2D mesh\n",
    "import color\n",
    "m2 = meshing_ats.Mesh2D(xyz_nodes,conn)\n",
    "m2.plot(color=['b','r','g','m','c','y','gray'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<matplotlib.collections.PolyCollection object at 0x1218cb5f8>\n"
     ]
    }
   ],
   "source": [
    "# check for non-star-convex cells\n",
    "non_star_convex = []\n",
    "for i,c in enumerate(conn):\n",
    "    points = [nodes[j] for j in c]\n",
    "    cv = star_convex(points)\n",
    "    if cv == -1:\n",
    "        c.reverse()\n",
    "    elif cv == 1:\n",
    "        # pass\n",
    "        0 == 0\n",
    "    else:\n",
    "        print (\"Non-star-convex cell:\", i, c)\n",
    "        plt.figure()\n",
    "        c2 = c[:]\n",
    "        c2.append(c2[0])\n",
    "        coords = xyz_nodes[c2]\n",
    "        plt.plot(coords[:,0],coords[:,1], 'b-x')\n",
    "        cent = centroid(points)\n",
    "        plt.scatter([cent.x[0],], [cent.x[1],], s=50, marker='s', c='r')\n",
    "        non_star_convex.append(i)\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "\n",
    "m2.plot(color=['b','r','g','m','c'],ax=ax)\n",
    "\n",
    "verts = [[xyz_nodes[i,0:2] for i in conn[p]] for p in non_star_convex]\n",
    "gons = collections.PolyCollection(verts, facecolors='r')\n",
    "ax.add_collection(gons)\n",
    "\n",
    "plt.show()\n",
    "print (gons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use VisIt to get IDs of High-centered polygons, the GIDs should be obtained in parallel runs\n",
    "path = '/Users/ajc/research/PreProcessing/python-scripts/meshes/watershed-barrow/'\n",
    "def read_poly_ids():\n",
    "    ids = []\n",
    "    with open(os.path.join(path,'poly_char_gids/manually_char_polygons_new.txt')) as f:\n",
    "        for line in f:\n",
    "            if 'Zone:' in line:\n",
    "                c = int(line.split()[1])\n",
    "                if not c in ids:\n",
    "                    ids.append(c)\n",
    "    return ids\n",
    "\n",
    "\n",
    "def get_ponded_depth():\n",
    "    d1 = h5py.File('/Users/ajc/Projects/ATS-Data/OR-CONDO/ats-intermediate-ngee/surface_only/Rain_R1-serial/visdump_surface_data.h5','r')\n",
    "    var = 'surface-ponded_depth.cell.0'\n",
    "    keys = np.array(d1[var].keys(), 'i')\n",
    "    keys = np.sort(keys, axis=None)\n",
    "    cycle = '%s'%keys[-1]\n",
    "    Ids_pd = d1[var][cycle][:]\n",
    "    \n",
    "    return Ids_pd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDS1= read_poly_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS2= read_poly_ids()\n",
    "#print (IDS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  23  24  25  26  27  29  30  31  32  33  34  35  36  37  38\n",
      "  45  46  47  48  49  50  52  53  54  55  56  58  59  60  61  62  63  64\n",
      "  65  66  67  68  75  76  77  78  79  88  90  96  99 103 105 106 107 108\n",
      " 110 114 117 118 119 120 121 128 129 131 152 154 155 163 166 167 177 178\n",
      " 193 202 217 219 227 236 237 238 239 246 248 249 250 251 253 254 255 256\n",
      " 257 258 259 260 261 262 264 265 266 270 274 275 276 277 278 279 280 281\n",
      " 282 283 284 285 286 287 288 289 290 291 292 293 295 296 297 298 299 300\n",
      " 314 315 316 317 318 319 322 324 325 327 328 329 330 331 332 333 334 335\n",
      " 336 337 338 339 340 341 342 344 345 346 351 352 353 354 364 368 441 442\n",
      " 443 444 445 446 447 448 449 450 451 452 453 457 458 460 461 464 465 466\n",
      " 467]\n"
     ]
    }
   ],
   "source": [
    "#id1=np.sort(IDS1)\n",
    "hcp_gids=np.sort(IDS2)\n",
    "#print (id1, hcp_gids)\n",
    "print (len(hcp_gids),hcp_gids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing organic layer thickness \n",
    "def org_layer_bottom_bndry(polygon, id):\n",
    "    if (polygon == 'HCP' and id % 2 == 0):\n",
    "        thickness = 0.1 \n",
    "    elif(polygon == 'HCP'):\n",
    "        thickness = 0.06 \n",
    "    elif (polygon == 'LCP' and id %3 == 0):\n",
    "        thickness = 0.2\n",
    "    else:\n",
    "        thickness = 0.16\n",
    "    return thickness\n",
    "\n",
    "def org_layer_bottom_bndry_gids(id):\n",
    "    if id in hcp_gids:\n",
    "        thickness = 0.1\n",
    "    else:\n",
    "        thickness= 0.2\n",
    "        \n",
    "    return thickness\n",
    "\n",
    "def irz_layer_bottom_bndry_gids(id,d_thick):\n",
    "    if id in hcp_gids:\n",
    "        thickness = d_thick #0.4\n",
    "    else:\n",
    "        thickness= 0.0\n",
    "    return thickness\n",
    "def org_layer_bottom_bndry_pd(pd):\n",
    "    pd = pd[0] * 100;\n",
    "    #print pd\n",
    "    if pd < 0.5:\n",
    "        thickness = 8.\n",
    "    elif (pd > 5.):\n",
    "        thickness = 20\n",
    "    elif (pd >=0.5 and pd<=5.0):\n",
    "        m = (20. - 8.)/(5.- 0.5)\n",
    "        y = 8. + m*(pd - 0.5)\n",
    "        thickness = np.floor(y) - np.floor(y)%2\n",
    "    return thickness/100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04\n",
      " 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12\n",
      " 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2\n",
      " 0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04\n",
      " 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12\n",
      " 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2\n",
      " 0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04\n",
      " 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12\n",
      " 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2\n",
      " 0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04\n",
      " 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12\n",
      " 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2\n",
      " 0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04\n",
      " 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12\n",
      " 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2\n",
      " 0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04\n",
      " 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12\n",
      " 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2\n",
      " 0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04\n",
      " 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12\n",
      " 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2\n",
      " 0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04\n",
      " 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12\n",
      " 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2\n",
      " 0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04\n",
      " 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12\n",
      " 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2\n",
      " 0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04\n",
      " 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12\n",
      " 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2\n",
      " 0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04\n",
      " 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12\n",
      " 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2  0.02 0.04 0.08 0.12 0.16 0.2\n",
      " 0.02 0.04 0.08 0.12 0.16 0.2 ]\n"
     ]
    }
   ],
   "source": [
    "#Ids = read_poly_ids()\n",
    "#ponded_depth = get_ponded_depth()\n",
    "gid_based = True\n",
    "\n",
    "peat_thickness = np.zeros(m2.num_cells())\n",
    "irz_thickness = np.zeros(m2.num_cells())\n",
    "hcp_irz = 0.5\n",
    "lcp_irz = 0.5\n",
    "\n",
    "\n",
    "\n",
    "if gid_based == True:\n",
    "    for i in range(m2.num_cells()):\n",
    "        if i in hcp_gids:\n",
    "            peat_thickness[i] = 0.1 #org_layer_bottom_bndry_gids(i)\n",
    "            irz_thickness[i] = hcp_irz#irz_layer_bottom_bndry_gids(i,d_thick=0.0)\n",
    "            #print ('HCP: ',i,peat_thickness[i])\n",
    "        else:\n",
    "            peat_thickness[i] = 0.2 #org_layer_bottom_bndry_gids(i)\n",
    "            irz_thickness[i] = lcp_irz #irz_layer_bottom_bndry_gids(i,d_thick=0.56)\n",
    "            #print ('LCP: ',i,peat_thickness[i])\n",
    "else:\n",
    "    for i in range(m2.num_cells()):\n",
    "        peat_thickness[i] = org_layer_bottom_bndry_pd(ponded_depth[i])\n",
    "        #print (i, peat_thickness[i], ponded_depth[i]*100)\n",
    "\n",
    "XX = [0.02,0.04,0.08,0.12,0.16,0.2]\n",
    "import itertools\n",
    "\n",
    "def get_next(iterable):\n",
    "    for item in itertools.cycle(iterable):\n",
    "        yield item\n",
    "\n",
    "pt = get_next(XX)\n",
    "for i in range(m2.num_cells()):\n",
    "    peat_thickness[i] = next(pt)\n",
    "    irz_thickness[i] = 0.5\n",
    "    \n",
    "print (peat_thickness)\n",
    "#print (irz_thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Ice rich zone 50 cm\n",
    "#variable peat thickness\n",
    "def make_mesh():\n",
    "    outfile = path\n",
    "    # layer extrusion\n",
    "    layer_types = []\n",
    "    layer_data = []\n",
    "    layer_ncells = []\n",
    "    layer_mat_ids = []\n",
    "\n",
    "\n",
    "    z=0\n",
    "    Z = []\n",
    "\n",
    "    for i in range(8):#10 \n",
    "        layer_types.append('constant')\n",
    "        layer_data.append(0.02)\n",
    "        layer_ncells.append(1)\n",
    "        layer_mat_ids.append(-10000*np.ones((m2.num_cells(),),'i'))\n",
    "        z = round(z + 0.02, 6)\n",
    "        Z.append(z)\n",
    "    print ('Peat ', z)\n",
    "\n",
    "    for i in range(17): #8cm peat, n=20, 20cm peat n = 14\n",
    "        layer_types.append('constant')\n",
    "        layer_data.append(0.02)\n",
    "        layer_ncells.append(1)\n",
    "        layer_mat_ids.append(1003*np.ones((m2.num_cells(),),'i'))\n",
    "        z = round(z + 0.02, 6)\n",
    "        Z.append(z)\n",
    "    print ('Upper mineral ', z)\n",
    "\n",
    "\n",
    "    dz = .02\n",
    "    for i in range(30):\n",
    "        dz *= 1.075\n",
    "        layer_types.append(\"constant\")\n",
    "        layer_data.append(dz)\n",
    "        layer_ncells.append(1)\n",
    "        layer_mat_ids.append(1004*np.ones((m2.num_cells(),),'i'))\n",
    "        z = round(z + dz,6)\n",
    "        Z.append(z)\n",
    "    print ('Ice rich', z)\n",
    "\n",
    "    for i in range(25):\n",
    "        dz *= 1.14\n",
    "        layer_types.append(\"constant\")\n",
    "        layer_data.append(dz)\n",
    "        layer_ncells.append(1)\n",
    "        layer_mat_ids.append(1005*np.ones((m2.num_cells(),),'i'))\n",
    "        z = round(z + dz,6)\n",
    "        Z.append(z)\n",
    "    print (z)\n",
    "\n",
    "\n",
    "\n",
    "    layer_types.append('snapped')\n",
    "    layer_data.append(-45.0) # bottom location\n",
    "    layer_ncells.append(1)\n",
    "    layer_mat_ids.append(1005*np.ones((m2.num_cells(),),'i'))\n",
    "\n",
    "\n",
    "    mat_ids=np.zeros((m2.num_cells(), 9), 'i')\n",
    "    #mat_ids=np.zeros((m2.num_cells(), 11), 'i')\n",
    "\n",
    "    for i in range(m2.num_cells()):\n",
    "        for j in range(9):\n",
    "            if j == 0 :\n",
    "                mat_ids[i,j]=1001\n",
    "            elif (Z[j] <= peat_thickness[i]):\n",
    "                #print (i,j,Z[j],peat_thickness[i])\n",
    "                mat_ids[i,j]=1002\n",
    "            else:\n",
    "                mat_ids[i,j]=1003\n",
    "        #break\n",
    "    for j in range(9):\n",
    "        layer_mat_ids[j] = mat_ids[:,j]\n",
    "\n",
    "    print ('HERE ',len(layer_mat_ids), len(layer_ncells), len(layer_types), len(layer_data))\n",
    "    #print (Z)\n",
    "    #print (layer_mat_ids[8])\n",
    "\n",
    "    m3 = meshing_ats.Mesh3D.extruded_Mesh2D(m2, layer_types, \n",
    "                                            layer_data, \n",
    "                                            layer_ncells, \n",
    "                                            layer_mat_ids)\n",
    "    print ('testing.exo'.split(\".\"))\n",
    "    #m3.write_exodus(\"testing.exo\")#\"barrow_polygon_watershed_5layer-icerich50cm-omvar.exo\")\n",
    "    #m3.write_exodus(os.path.join(outfile + 'barrow_polygon_watershed_5layer-icerich50cm-omvar.exo').encode('utf8'))\n",
    "    m3.write_exodus('barrow_polygon_watershed_5layer-icerich50cm-omvar.exo'.encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ice rich zone 40 cm for LCP, and 50 cm for HCP\n",
    "#variable peat thickness\n",
    "# layer extrusion\n",
    "def make_mesh_variable_irz_om():\n",
    "    layer_types = []\n",
    "    layer_data = []\n",
    "    layer_ncells = []\n",
    "    layer_mat_ids = []\n",
    "\n",
    "    z=0\n",
    "    Z = []\n",
    "    peat_layer_cells = 10\n",
    "    var_layer_cells_irz = 20 #26 cells covers 80 cm\n",
    "    #irz_start_cell_id = var_layer_cells + var_layer_cells_irz\n",
    "    irz_start_cell=1 #10 for irz=40, 16\n",
    "    \n",
    "    Ncells = 0\n",
    "    for i in range(peat_layer_cells):\n",
    "        layer_types.append('constant')\n",
    "        layer_data.append(0.02)\n",
    "        layer_ncells.append(1)\n",
    "        layer_mat_ids.append(-10000*np.ones((m2.num_cells(),),'i'))\n",
    "        z = round(z + 0.02, 6)\n",
    "        Z.append(z)\n",
    "        Ncells +=1\n",
    "    print ('Organic matter thickness: ', Ncells, z)\n",
    "\n",
    "    for i in range(10): \n",
    "        layer_types.append('constant')\n",
    "        layer_data.append(0.02)\n",
    "        layer_ncells.append(1)\n",
    "        layer_mat_ids.append(1003*np.ones((m2.num_cells(),),'i'))\n",
    "        z = round(z + 0.02, 6)\n",
    "        Z.append(z)\n",
    "        Ncells +=1\n",
    "    print ('Upper mineral 1: ', Ncells, z)\n",
    "\n",
    "    dz = .02 #keep the top 60 cm to 2cm resolution\n",
    "    for i in range(var_layer_cells_irz):\n",
    "        #dz *= 1.025\n",
    "        dz = 0.02\n",
    "        dz = np.round(dz,4)\n",
    "        layer_types.append(\"constant\")\n",
    "        layer_data.append(dz)\n",
    "        layer_ncells.append(1)\n",
    "        layer_mat_ids.append(-1004*np.ones((m2.num_cells(),),'i'))\n",
    "        z = round(z + dz,6)\n",
    "        Z.append(z)\n",
    "        Ncells +=1\n",
    "    print ('Ice rich zone 1: ', Ncells, z, Z[-1])\n",
    "\n",
    "    #dz = .02\n",
    "    for i in range(20):\n",
    "        dz *= 1.125\n",
    "        dz = np.round(dz,4)\n",
    "        layer_types.append(\"constant\")\n",
    "        layer_data.append(dz)\n",
    "        layer_ncells.append(1)\n",
    "        layer_mat_ids.append(1004*np.ones((m2.num_cells(),),'i'))\n",
    "        z = round(z + dz,6)\n",
    "        Z.append(z)\n",
    "        Ncells +=1\n",
    "    print ('Ice rich zone 2: ', Ncells, z, Z[-1])\n",
    "\n",
    "    for i in range(19):\n",
    "        dz *= 1.2\n",
    "        dz = np.round(dz,4)\n",
    "        layer_types.append(\"constant\")\n",
    "        layer_data.append(dz)\n",
    "        layer_ncells.append(1)\n",
    "        layer_mat_ids.append(1005*np.ones((m2.num_cells(),),'i'))\n",
    "        z = round(z + dz,6)\n",
    "        Z.append(z)\n",
    "    print ('Mineral ',z, Z[-1])\n",
    "\n",
    "\n",
    "    layer_types.append('snapped')\n",
    "    layer_data.append(-45.0) # bottom location\n",
    "    layer_ncells.append(1)\n",
    "    layer_mat_ids.append(1005*np.ones((m2.num_cells(),),'i'))\n",
    "\n",
    "    #---------------------------------------------------------------\n",
    "    # Assign variable peat layers\n",
    "    mat_ids=np.zeros((m2.num_cells(), peat_layer_cells), 'i')\n",
    "    test_id =-1\n",
    "    for i in range(m2.num_cells()):\n",
    "        for j in range(peat_layer_cells):\n",
    "            if j == 0 :\n",
    "                mat_ids[i,j]=1001\n",
    "            elif (Z[j] <= peat_thickness[i]):\n",
    "                #print (i,j,Z[j],peat_thickness[i])\n",
    "                mat_ids[i,j]=1002\n",
    "                test_id=1002\n",
    "            else:\n",
    "                mat_ids[i,j]=1003\n",
    "                test_id=1003\n",
    "        #print (i,peat_thickness[i],test_id)\n",
    "    #print ('HCP: ', hcp_gids[44], layer_mat_ids[9][214])\n",
    "    for j in range(peat_layer_cells):\n",
    "        \n",
    "        layer_mat_ids[j] = mat_ids[:,j]\n",
    "        #print ('J: ',j, layer_mat_ids[j])\n",
    "    \n",
    "    print ('HCP: ', hcp_gids[44], layer_mat_ids[8][58])\n",
    "    \n",
    "    #---------------------------------------------------------------\n",
    "    #for i in range(37):\n",
    "    #    print (i, layer_mat_ids[i][261])\n",
    "    #---------------------------------------------------------------\n",
    "    # Assign variable ice rich zone layers\n",
    "    mat_ids=np.zeros((m2.num_cells(), var_layer_cells_irz), 'i')\n",
    "    for i in range(m2.num_cells()):\n",
    "        #print ('TOP', i, hcp_gids[i])\n",
    "        for j in range(var_layer_cells_irz):\n",
    "            if (Z[20+j] > irz_thickness[i]):\n",
    "                #print ('IRZ',i,j,Z[19+j],irz_thickness[i])\n",
    "                mat_ids[i,j]=1004\n",
    "            else:\n",
    "                #print ('No IRZ ',i,j,Z[20+j],irz_thickness[i])\n",
    "                mat_ids[i,j]=1003\n",
    "\n",
    "    for j in range(20,20+var_layer_cells_irz):#starts at 20 due to 40 cm depth of ice rich zone\n",
    "        layer_mat_ids[j] = mat_ids[:,j-20]\n",
    "    \n",
    "    #---------------------------------------------------------------\n",
    "    #for i in range(37):\n",
    "    #    print ('A: ',Z[i], i, layer_mat_ids[i][262])\n",
    "    #print ('HERE ',len(layer_mat_ids), len(layer_ncells), len(layer_types), len(layer_data))\n",
    "    #print (Z)\n",
    "    #print (layer_mat_ids)\n",
    "\n",
    "    m3 = meshing_ats.Mesh3D.extruded_Mesh2D(m2, layer_types, \n",
    "                                            layer_data, \n",
    "                                            layer_ncells, \n",
    "                                            layer_mat_ids)#,hcp_gids)\n",
    "\n",
    "    #m3.write_exodus('barrow_polygon_watershed_5layer-var_irz5050_var_om_test.exo'.encode('utf8'))\n",
    "    m3.write_exodus('barrow_polygon_watershed_5layer-var_irz5050_var_om_movie.exo'.encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organic matter thickness:  10 0.2\n",
      "Upper mineral 1:  20 0.4\n",
      "Ice rich zone 1:  40 0.8 0.8\n",
      "Ice rich zone 2:  60 2.519 2.519\n",
      "Mineral  41.6886 41.6886\n",
      "HCP:  54 1003\n",
      "\n",
      "You are using exodus.py v 1.16 (seacas-py3), a python wrapper of some of the exodus library.\n",
      "\n",
      "Copyright (c) 2013, 2014, 2015, 2016, 2017, 2018, 2019 National Technology &\n",
      "Engineering Solutions of Sandia, LLC (NTESS).  Under the terms of\n",
      "Contract DE-NA0003525 with NTESS, the U.S. Government retains certain\n",
      "rights in this software.\n",
      "\n",
      "BASENAME_FILE_Exodus:  barrow_polygon_watershed_5layer-var_irz5050_var_om_movie.exo\n",
      "barrow_polygon_watershed_5layer-var_irz5050_var_om_movie\n",
      "Opening exodus file: barrow_polygon_watershed_5layer-var_irz5050_var_om_movie.exo\n",
      "Closing exodus file: barrow_polygon_watershed_5layer-var_irz5050_var_om_movie.exo\n"
     ]
    }
   ],
   "source": [
    "make_mesh_variable_irz_om()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write subgrid parameters to .h5 file\n",
    "import h5py\n",
    "infile = h5py.File('/Users/ajc/FUSE/simulations/production/old/polygonal_tundra.new/data_sg_para/sg_para-watershed468-new.h5','r')\n",
    "outfile = h5py.File('/Users/ajc/FUSE/simulations/production/barrow_watershed/data/sg_parameters/sg_para-watershed468_1204.h5','w')\n",
    "#hcp_gids\n",
    "dmax = np.ones(468)*0.361\n",
    "dex = np.ones(468)*0.361/2\n",
    "delta = np.ones(468)*0.15\n",
    "beta = np.ones(468)*7.0\n",
    "for h in hcp_gids:\n",
    "    dmax[h] = 0.416\n",
    "    dex[h] = 0.228\n",
    "    delta[h] = 0.08\n",
    "    beta[h] = 1.5\n",
    "for key in infile.keys():\n",
    "    if not 'time' in key:\n",
    "        d = infile[key]['0'][:1]\n",
    "        grp = outfile.create_group(key)\n",
    "        if 'microtopographic_relief' in key:\n",
    "            grp.create_dataset('0',data=dmax)\n",
    "        if 'excluded_volume' in key:\n",
    "            grp.create_dataset('0',data=dex)\n",
    "        if 'depression_depth' in key:\n",
    "            grp.create_dataset('0',data=delta)\n",
    "        if 'drag_exponent' in key:\n",
    "            grp.create_dataset('0',data=beta)\n",
    "    else:\n",
    "        outfile.create_dataset('time',data=infile[key])\n",
    "        #print (key,d[:4])\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "points = np.random.rand(4, 2)   # 30 random points in 2-D\n",
    "hull = ConvexHull(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(points[:,0], points[:,1], 'o')\n",
    "for simplex in hull.simplices:\n",
    "    plt.plot(points[simplex, 0], points[simplex, 1], 'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
